{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "# Goal\n",
    "Create a data pipeline for twitter challenge.\n",
    "\n",
    "# Methodology\n",
    "Create different features from the original data\n",
    "\n",
    "## Sections\n",
    "1. [**Requirements**](#Requirements)\n",
    "2. [**Functions**](#Functions)\n",
    "3. [**Inputs**](#Inputs)\n",
    "4. [**Pipeline**](#Pipeline)\n",
    "    - [**Indicators**](#Indicators)\n",
    "    - [**Intention_features**](#Intention_features)\n",
    "    - [**TopicEncodings**](#TopicEncodings)\n",
    "    - [**EngagingFollowsEngaged**](#EngagingFollowsEngaged)\n",
    "    - [**Hashtags**](#Hashtags)\n",
    "    - [**Domain**](#Domain)\n",
    "    - [**Language**](#Language)\n",
    "    - [**Media**](#Media)\n",
    "    - [**Links**](#Links)\n",
    "    - [**Tweet_type**](#Tweet_type)\n",
    "    - [**Timestamp_features**](#Timestamp_features)\n",
    "    - [**Followers_and_Followings_features**](#Followers_and_Followings_features)\n",
    "    - [**Quantile_Discretizer**](#Quantile_Discretizer)\n",
    "    - [**Intentions_join**](#Intentions_join)\n",
    "5. [**FeatureSelection**](#FeatureSelection)\n",
    "6. [**Imputation**](#Imputation)\n",
    "7. [**Validation**](#Validation)\n",
    "8. [**Saving_df**](#Saving_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f9b198e17345dbb40039cd282d9876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1591231044582_0002</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting python-dateutil>=2.6.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas) (1.14.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-1.0.4 python-dateutil-2.8.1\n",
      "\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.13.22-py2.py3-none-any.whl (128 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Using cached s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting botocore<1.17.0,>=1.16.22\n",
      "  Using cached botocore-1.16.22-py2.py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Using cached docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\"\n",
      "  Using cached urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /mnt/tmp/1591231481865-0/lib/python3.6/site-packages (from botocore<1.17.0,>=1.16.22->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.17.0,>=1.16.22->boto3) (1.13.0)\n",
      "Installing collected packages: docutils, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.13.22 botocore-1.16.22 docutils-0.15.2 s3transfer-0.3.3 urllib3-1.25.9"
     ]
    }
   ],
   "source": [
    "#installing packages\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d22c3fd4f6340839df6bb28fc045498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reconfiguring SparkContext\n",
    "sc.setCheckpointDir('hdfs:///twitter/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6254bcb8c3bc44308d2c313fa2be51fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048M\n",
      "1000"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyspark\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (FloatType, DateType, StructType, StructField, StringType, LongType, \n",
    "    IntegerType, ArrayType, BooleanType, DoubleType)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, QuantileDiscretizer\n",
    "gc.enable()\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", 1000).appName(\"twitter\").getOrCreate()\n",
    "print(spark.sparkContext.getConf().get('spark.driver.memory'))\n",
    "print(spark.sparkContext.getConf().get(\"spark.sql.shuffle.partitions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a056aaa72e4152a24179ff680e7cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_data(path='training.tsv', has_labels=True, schema='auto'):\n",
    "    \"\"\"\n",
    "    Parses the training data for the Twitter RecSys Challenge.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.appName(\"twitter\").getOrCreate()\n",
    "    if schema == 'auto':\n",
    "        schema = build_schema(has_labels)\n",
    "    df = spark.read.csv(path, schema=schema, sep='\\x01', encoding='utf-8',\n",
    "                        ignoreLeadingWhiteSpace=True, ignoreTrailingWhiteSpace=True)\n",
    "    df = df.withColumn('text_tokens', F.split('text_tokens', '\\t'))\n",
    "    df = df.withColumn('hashtags', F.split('hashtags', '\\t'))\n",
    "    df = df.withColumn('present_media', F.split('present_media', '\\t'))\n",
    "    df = df.withColumn('present_links', F.split('present_links', '\\t'))\n",
    "    df = df.withColumn('present_domains', F.split('present_domains', '\\t'))\n",
    "    return df\n",
    "\n",
    "def build_schema(has_labels=True):\n",
    "    if has_labels:\n",
    "        schema = StructType([StructField('text_tokens', StringType()),\n",
    "                             StructField('hashtags', StringType()),\n",
    "                             StructField('tweet_id', StringType()),\n",
    "                             StructField('present_media', StringType()),\n",
    "                             StructField('present_links', StringType()),\n",
    "                             StructField('present_domains', StringType()),\n",
    "                             StructField('tweet_type', StringType()),\n",
    "                             StructField('language', StringType()),\n",
    "                             StructField('tweet_timestamp', LongType()),\n",
    "                             StructField('engaged_with_user_id', StringType()),\n",
    "                             StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                             StructField('engaged_with_user_account_creation', LongType()),\n",
    "                             StructField('engaging_user_id', StringType()),\n",
    "                             StructField('engaging_user_follower_count', IntegerType()),\n",
    "                             StructField('engaging_user_following_count', IntegerType()),\n",
    "                             StructField('engaging_user_is_verified', BooleanType()),\n",
    "                             StructField('engaging_user_account_creation', LongType()),\n",
    "                             StructField('engagee_follows_engager', BooleanType()),\n",
    "                             StructField('reply_timestamp', LongType()),\n",
    "                             StructField('retweet_timestamp', LongType()),\n",
    "                             StructField('retweet_with_comment_timestamp', LongType()),\n",
    "                             StructField('like_timestamp', LongType())\n",
    "                            ])\n",
    "    else:\n",
    "         schema = StructType([StructField('text_tokens', StringType()),\n",
    "                             StructField('hashtags', StringType()),\n",
    "                             StructField('tweet_id', StringType()),\n",
    "                             StructField('present_media', StringType()),\n",
    "                             StructField('present_links', StringType()),\n",
    "                             StructField('present_domains', StringType()),\n",
    "                             StructField('tweet_type', StringType()),\n",
    "                             StructField('language', StringType()),\n",
    "                             StructField('tweet_timestamp', LongType()),\n",
    "                             StructField('engaged_with_user_id', StringType()),\n",
    "                             StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                             StructField('engaged_with_user_account_creation', LongType()),\n",
    "                             StructField('engaging_user_id', StringType()),\n",
    "                             StructField('engaging_user_follower_count', IntegerType()),\n",
    "                             StructField('engaging_user_following_count', IntegerType()),\n",
    "                             StructField('engaging_user_is_verified', BooleanType()),\n",
    "                             StructField('engaging_user_account_creation', LongType()),\n",
    "                             StructField('engagee_follows_engager', BooleanType())\n",
    "                            ])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebbab3805d04e27a8ad04062a8fdbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_pkl_to_s3(obj, key_filename, bucket_name):\n",
    "    serialized_obj = pickle.dumps(obj)\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket_name, Key=key_filename, \n",
    "                  Body=serialized_obj)\n",
    "    \n",
    "def hdfs_exists(path):\n",
    "    proc = subprocess.Popen(['hadoop', 'fs', '-test', '-e', path])\n",
    "    proc.communicate()\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"{path} does not exist\")\n",
    "        return False\n",
    "    else : \n",
    "        print(f\"{path} exist\")\n",
    "        return True\n",
    "    \n",
    "def validator(df):\n",
    "    columns_w_nan = {}\n",
    "    for col in df.schema:\n",
    "        null_count = df.filter(F.col(col.name).isNull()).count()\n",
    "        if null_count>0:\n",
    "            columns_w_nan[col.name]=null_count\n",
    "    return columns_w_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e70e029f864daab6828b4e78c331a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary_size={\"final-complete\": {\"val_size\": 500000, \n",
    "                                    \"train_size\": \"all\"}}\n",
    "\n",
    "training = False\n",
    "smaller_train = True\n",
    "submission = False\n",
    "test = False\n",
    "\n",
    "bucket='bucket-name'\n",
    "s3_resource = boto3.resource('s3')\n",
    "top_k_languages = 30\n",
    "top_k_domains = 3000\n",
    "top_k_hashtags = 13000\n",
    "\n",
    "# Embeddings\n",
    "num_partitions=1000\n",
    "\n",
    "# Buckets\n",
    "partition_per_cluster = 100\n",
    "\n",
    "suffix_sample = \"final-complete\" #\"full\", \"small\", \"medium\", \"sub_medium\"\n",
    "data_path = \"final-data\"\n",
    "object_paths = \"final-artifacts\"\n",
    "\n",
    "val_size = dictionary_size[suffix_sample][\"val_size\"]\n",
    "train_size = dictionary_size[suffix_sample][\"train_size\"]\n",
    "\n",
    "bucket_s3 = s3_resource.Bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e1fc34a4cf4e68ac955bf61decf2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#S3\n",
    "twitter_bucket_s3 = \"s3a://bucket-name\"\n",
    "trainining_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"training.tsv\")\n",
    "submission_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"submission.tsv\")\n",
    "test_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"test.tsv\")\n",
    "\n",
    "# Splitted paths\n",
    "train_path = os.path.join(twitter_bucket_s3, data_path, \"train-\"+suffix_sample)\n",
    "val_path = os.path.join(twitter_bucket_s3, data_path, \"val-\"+suffix_sample)\n",
    "\n",
    "# Processed\n",
    "processed_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"smaller-train-\"+suffix_sample)\n",
    "processed_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"val-\"+suffix_sample)\n",
    "processed_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"submission-\"+suffix_sample)\n",
    "processed_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"test-\"+suffix_sample)\n",
    "processed_emb_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_emb_smaller_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                        \"smaller-train-\"+suffix_sample)\n",
    "processed_emb_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_emb_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"submission-\"+suffix_sample)\n",
    "processed_emb_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"test-\"+suffix_sample)\n",
    "processed_top_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_top_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_top_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"submission-\"+suffix_sample)\n",
    "processed_top_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"test-\"+suffix_sample)\n",
    "# Resources\n",
    "engaging_users_training_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-training\")\n",
    "engaging_users_submission_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-submission\")\n",
    "engaging_users_test_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-test\")\n",
    "intentions_path = os.path.join(twitter_bucket_s3, data_path, \"intentions-\"+suffix_sample)\n",
    "map_user_bucket_path = os.path.join(twitter_bucket_s3, data_path, \"map_user_bucket\")\n",
    "\n",
    "topic_encodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"user_topics\")\n",
    "users_intime_path = os.path.join(twitter_bucket_s3, data_path, \"users_intime-\"+suffix_sample)\n",
    "\n",
    "# keys objects\n",
    "key_hashtag_mapping = os.path.join(object_paths, f'hashtag_mapping_{suffix_sample}.pkl')\n",
    "key_domain_mapping = os.path.join(object_paths, f'domain_mapping_{suffix_sample}.pkl')\n",
    "key_language_mapping = os.path.join(object_paths, f'language_mapping_{suffix_sample}.pkl')\n",
    "key_hashtag_count = os.path.join(object_paths, f'hashtag_count_{suffix_sample}.pkl')\n",
    "key_domain_count = os.path.join(object_paths, f'domain_count_{suffix_sample}.pkl')\n",
    "key_scaling_features = os.path.join(object_paths, f'scaling_dictionary_{suffix_sample}.pkl')\n",
    "key_diff_min = os.path.join(object_paths, f'diff_min_{suffix_sample}.pkl')\n",
    "key_impute_perc = os.path.join(object_paths, f'dict_mean_perc_{suffix_sample}.pkl')\n",
    "key_topiccount = os.path.join(object_paths, f'topiccount_{suffix_sample}.pkl')\n",
    "\n",
    "# s3+keys\n",
    "columns = [\"engaged_with_user_follower_count\", \"engaged_with_user_following_count\",\n",
    "           \"engaged_with_user_account_creation\", \"engaging_user_follower_count\",\n",
    "           \"engaging_user_following_count\", \"engaging_user_account_creation\"]\n",
    "qds_paths = {}\n",
    "for col in columns:\n",
    "    qds_paths[col] = os.path.join(twitter_bucket_s3, object_paths, f\"qs_{suffix_sample}_\" + col)\n",
    "    \n",
    "# Bucket pipeline\n",
    "users_buckets = os.path.join(twitter_bucket_s3, data_path, \"users_buckets\") #\n",
    "users_buckets_part_2 = os.path.join(twitter_bucket_s3, data_path, \"users_buckets_part_2\") #\n",
    "\n",
    "pipeline_kmeans_path = os.path.join(twitter_bucket_s3, object_paths, \"pipeline_id_encoding\")\n",
    "cluster_map_path = os.path.join(twitter_bucket_s3, data_path, \"cluster_map\")\n",
    "\n",
    "# Embeddings\n",
    "bert_embeddings_train = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"tweets_extended\")\n",
    "submission_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \n",
    "                                                 \"submission-tweets-extended\")\n",
    "test_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"test-tweets-extended\")\n",
    "\n",
    "# Topics pipeline\n",
    "reduced_topics_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"reducedTopics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load intentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ac65e68f7c43b08d45578538c9927b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    schema = StructType([StructField('engaging_user_id', StringType()),\n",
    "                         StructField('total_appearance', LongType()),\n",
    "                         StructField('perc_n_interactions', DoubleType()),\n",
    "                         StructField('perc_n_commented', DoubleType()),\n",
    "                         StructField('perc_n_liked', DoubleType()),\n",
    "                         StructField('perc_n_replied', DoubleType()),\n",
    "                         StructField('perc_n_retweeted', DoubleType())])\n",
    "    intention_df = spark.read.csv(intentions_path, schema=schema)\n",
    "    user_id_train = intention_df.select(\"engaging_user_id\")\n",
    "    user_id_train = user_id_train.withColumn(\"hash_engaging_user_id\", \n",
    "                                             F.abs(F.hash(\"engaging_user_id\")%num_partitions))\n",
    "    user_id_train = user_id_train.repartition(\"hash_engaging_user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load reducedTopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d511c3dd84004da89928c2437a2665ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    reduced_topics = spark.read.parquet(reduced_topics_path)\n",
    "    reduced_topics = reduced_topics.drop(\"hash\")\n",
    "    reduced_topics = reduced_topics.select('engaging_user_id', \n",
    "                              F.col('rp0_topic').alias(\"0_topic\"), \n",
    "                              F.col('rp1_topic').alias(\"1_topic\"), \n",
    "                              F.col('rp2_topic').alias(\"2_topic\"), \n",
    "                              F.col('rp3_topic').alias(\"3_topic\"), \n",
    "                              F.col('rp4_topic').alias(\"4_topic\"), \n",
    "                              F.col('rp0_topiccount').alias(\"0_topiccount\"),\n",
    "                              F.col('rp1_topiccount').alias(\"1_topiccount\"), \n",
    "                              F.col('rp2_topiccount').alias(\"2_topiccount\"), \n",
    "                              F.col('rp3_topiccount').alias(\"3_topiccount\"), \n",
    "                              F.col('rp4_topiccount').alias(\"4_topiccount\"), \n",
    "                              'rp0_topicprop', 'rp1_topicprop', 'rp2_topicprop', 'rp3_topicprop', 'rp4_topicprop', \n",
    "                              'rt0_topicprop', 'rt1_topicprop', 'rt2_topicprop', 'rt3_topicprop', 'rt4_topicprop', \n",
    "                              'rtc0_topicprop', 'rtc1_topicprop', 'rtc2_topicprop', 'rtc3_topicprop', 'rtc4_topicprop', \n",
    "                              'lk0_topicprop', 'lk1_topicprop', 'lk2_topicprop', 'lk3_topicprop', 'lk4_topicprop')\n",
    "    reduced_topics = reduced_topics.withColumn(\"hash_engaging_user_id\", \n",
    "                                                 F.abs(F.hash(\"engaging_user_id\")%num_partitions))\n",
    "    reduced_topics = reduced_topics.repartition(\"hash_engaging_user_id\")\n",
    "    reduced_topics = reduced_topics.withColumnRenamed(\"hash_engaging_user_id\", \"hash_engaging_user_id_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining limited users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fdb997552e4a4a9183fb8f025971d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced_topics_train_path = \"hdfs:///reduced_topics_train\"\n",
    "topiccount_cols = [\"0_topiccount\", \"1_topiccount\", \"2_topiccount\", \"3_topiccount\", \"4_topiccount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73dad067454440b8f0c11018707cc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    topiccount_cols = [\"0_topiccount\", \"1_topiccount\", \"2_topiccount\", \"3_topiccount\", \"4_topiccount\"]\n",
    "    reduced_topics_train = user_id_train.join(reduced_topics, \n",
    "                                              on=\"engaging_user_id\", how=\"left\")\n",
    "    reduced_topics_train = reduced_topics_train.drop(\"hash_engaging_user_id_1\")\n",
    "    reduced_topics_train = reduced_topics_train.withColumnRenamed(\"hash_engaging_user_id\", \"hash_engaging_user_id_1\")\n",
    "    for col_i in topiccount_cols:\n",
    "        reduced_topics_train_log = reduced_topics_train.withColumn(col_i, F.log(F.col(col_i)+1))\n",
    "        \n",
    "    topiccount_0 = reduced_topics_train_log.select(F.col(\"0_topiccount\").alias(\"topiccount\"))\n",
    "    topiccount_1 = reduced_topics_train_log.select(F.col(\"1_topiccount\").alias(\"topiccount\"))\n",
    "    topiccount_2 = reduced_topics_train_log.select(F.col(\"2_topiccount\").alias(\"topiccount\"))\n",
    "    topiccount_3 = reduced_topics_train_log.select(F.col(\"3_topiccount\").alias(\"topiccount\"))\n",
    "    topiccount_4 = reduced_topics_train_log.select(F.col(\"4_topiccount\").alias(\"topiccount\"))\n",
    "    \n",
    "    topiccount = topiccount_0.union(topiccount_1)\n",
    "    topiccount = topiccount.union(topiccount_2)\n",
    "    topiccount = topiccount.union(topiccount_3)\n",
    "    topiccount = topiccount.union(topiccount_4)\n",
    "\n",
    "    topiccount_mean, topiccount_std = topiccount.select(F.mean(\"topiccount\"), F.stddev(\"topiccount\")).first()\n",
    "    # Saving scaling features\n",
    "    scaling_topiccount_dict = {'mean': topiccount_mean, 'std': topiccount_std}\n",
    "    save_pkl_to_s3(scaling_topiccount_dict, key_topiccount, bucket)\n",
    "    reduced_topics_train.write.option(\"header\", \"true\").csv(reduced_topics_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2d2127321040e08b5dc5bb8c4cba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller Train"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    current_hdfs_path = \"hdfs:///submission-df\"\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    current_hdfs_path = \"hdfs:///test-df\"\n",
    "elif training:\n",
    "    print(\"Train\")\n",
    "    current_hdfs_path = \"hdfs:///train-df\"\n",
    "elif smaller_train:\n",
    "    print(\"Smaller Train\")\n",
    "    current_hdfs_path = \"hdfs:///smaller-train-df\"\n",
    "else:\n",
    "    print(\"Valid\")\n",
    "    current_hdfs_path = \"hdfs:///valid-df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca03fd4e21e4930bb61514e5329b0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller Train"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_emb_submission_path)\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_emb_test_path)\n",
    "elif training:\n",
    "    print(\"Train\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_emb_train_path)\n",
    "elif smaller_train:\n",
    "    print(\"Smaller Train\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_emb_smaller_train_path)\n",
    "else:\n",
    "    print(\"Valid\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_emb_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de8104279fc4884b002ff3bf125a299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn(\"hash_engaging_user_id\", F.abs(F.hash(\"engaging_user_id_id\")%num_partitions))\n",
    "df = df.repartition(\"hash_engaging_user_id\")\n",
    "df.write.option(\"header\",\"true\").csv(current_hdfs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005957be9b5d4f02abab303d2202e90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF JOIN TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d544c354b655486684c51649059f3d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaling_topiccount_dict = pickle.loads(s3_resource.Bucket(bucket).Object(key_topiccount).get()['Body'].read())\n",
    "assert type(scaling_topiccount_dict) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc73e8bb30f43dd88270852ada0ef61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced_topics_train = spark.read.option(\"header\", \"true\").csv(reduced_topics_train_path)\\\n",
    "                        .repartition(\"hash_engaging_user_id_1\")\n",
    "for col_i in topiccount_cols:\n",
    "    reduced_topics_train = reduced_topics_train.withColumn(col_i,F.col(col_i).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73861d2f6bb4a8e9a2eca5b8193c0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(current_hdfs_path).repartition(\"hash_engaging_user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab8440121d142d297efa0c3b9a002fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000"
     ]
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b719aea09db941c3a2a6a1aaa264fce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.join(reduced_topics_train,\n",
    "             df.engaging_user_id_id==reduced_topics_train.engaging_user_id,\n",
    "             how=\"left\")\n",
    "df = df.drop(\"engaging_user_id\", \"hash_engaging_user_id_1\", \"hash_engaging_user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025acb818dee4b7eb64488b3a767398b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_count_columns = [i for i in df.columns if \"topiccount\" in i]\n",
    "topic_prop_columns = [i for i in df.columns if \"topicprop\" in i]\n",
    "topic_columns = [i for i in df.columns if i.endswith(\"_topic\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fd3481c09f48e794049654049afde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_i in topic_columns:\n",
    "    df = df.withColumn(col_i, F.when(F.col(col_i).isNotNull(), F.col(col_i)).otherwise(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab630f3ea494f57a49dfa1669d20ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_i in topic_prop_columns:\n",
    "    df = df.withColumn(col_i, F.when(F.col(col_i).isNotNull(), F.col(col_i)).otherwise(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2096b81826f4e3eadb8a379ea4ffaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_i in topic_count_columns:\n",
    "    df = df.withColumn(col_i, F.when(F.col(col_i).isNotNull(), F.col(col_i)).otherwise(0.0))\n",
    "    df = df.withColumn(col_i, F.log(F.col(col_i)+1))\n",
    "    df = df.withColumn(col_i, \n",
    "                       (F.col(col_i)-scaling_topiccount_dict[\"mean\"])/(2*scaling_topiccount_dict[\"std\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865d51f2316041aea2dd21d603edbf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "validator(df.select(\"3_topic\", \"2_topiccount\", \"rp1_topicprop\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3441e2d31cdd4f578b88dc24dff80c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller Train"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    final_hdfs_path = \"hdfs:///submission-final-topics\"\n",
    "    df.write.option(\"header\",\"true\").csv(final_hdfs_path)\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    final_hdfs_path = \"hdfs:///test-final-topics\"\n",
    "    df.write.option(\"header\",\"true\").csv(final_hdfs_path)\n",
    "elif training:\n",
    "    print(\"Train\")\n",
    "    final_hdfs_path = \"hdfs:///train-final-topics\"\n",
    "    df.write.option(\"header\",\"true\").csv(final_hdfs_path)\n",
    "elif smaller_train:\n",
    "    print(\"Smaller Train\")\n",
    "    final_hdfs_path = \"hdfs:///smaller-train-final-topics\"\n",
    "    df.write.option(\"header\",\"true\").csv(final_hdfs_path)\n",
    "else:\n",
    "    print(\"Valid\")\n",
    "    final_hdfs_path = \"hdfs:///val-final-topics\"\n",
    "    df.write.option(\"header\",\"true\").csv(final_hdfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([(StructField(\"text_tokens_ors\",StringType(),true),\n",
    "                     StructField(\"tweet_id_id\",StringType(),true),\n",
    "                     StructField(\"engaged_with_user_id_id\",StringType(),true),\n",
    "                     StructField(\"engaged_with_user_is_verified_bool\",BooleanType(),true),\n",
    "                     StructField(\"engaging_user_id_id\",StringType(),true),\n",
    "                     StructField(\"engaging_user_is_verified_bool\",BooleanType(),true),\n",
    "                     StructField(\"engagee_follows_engager_bool\",BooleanType(),true),\n",
    "                     StructField(\"hashtagEncoded_unors\",StringType(),true),\n",
    "                     StructField(\"hashtagSumCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"hashtagCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"domainEncoded_unors\",StringType(),true),\n",
    "                     StructField(\"domainCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"tweetEncoded_cat\",IntegerType(),true),\n",
    "                     StructField(\"languageEncoded_cat\",StringType(),true),\n",
    "                     StructField(\"tweet_timestamp_day_of_week_cat\",StringType(),true),\n",
    "                     StructField(\"tweet_timestamp_week_of_month_cat\",StringType(),true),\n",
    "                     StructField(\"tweet_timestamp_hour_cat\",StringType(),true),\n",
    "                     StructField(\"tweet_timestamp_to_engagee_account_creation_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"tweet_timestamp_to_engaging_account_creation_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_vs_engaging_follower_diff_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_vs_engaging_following_diff_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_follow_diff_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaging_follow_diff_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_follower_diff_engaging_following_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_following_diff_engaging_follower_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_user_follower_count_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaging_user_follower_count_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_user_following_count_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaging_user_following_count_log_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"PhotoCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"VideoCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"GIFCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"linkCount_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_user_follower_count_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_user_following_count_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"engaged_with_user_account_creation_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"engaging_user_follower_count_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"engaging_user_following_count_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"engaging_user_account_creation_q_cat\",DoubleType(),true),\n",
    "                     StructField(\"total_appearance_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"perc_n_interactions_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"perc_n_commented_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"perc_n_liked_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"perc_n_replied_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"perc_n_retweeted_ss_num\",DoubleType(),true),\n",
    "                     StructField(\"indicator_reply\",IntegerType(),true),\n",
    "                     StructField(\"indicator_retweet\",IntegerType(),true),\n",
    "                     StructField(\"indicator_retweet_with_comment\",IntegerType(),true),\n",
    "                     StructField(\"indicator_like\",IntegerType(),true),\n",
    "                     StructField(\"indicator_interaction\",IntegerType(),true),\n",
    "                     StructField(\"engaged_with_user_id_bucket\",IntegerType(),true),\n",
    "                     StructField(\"engaging_user_id_bucket\",IntegerType(),true),\n",
    "                     StructField(\"hash_engaging_user_id\",IntegerType(),true),\n",
    "                     StructField(\"rp0_topic\",IntegerType(),true),\n",
    "                     StructField(\"rp1_topic\",IntegerType(),true),\n",
    "                     StructField(\"rp2_topic\",IntegerType(),true),\n",
    "                     StructField(\"rp3_topic\",IntegerType(),true),\n",
    "                     StructField(\"rp4_topic\",IntegerType(),true),\n",
    "                     StructField(\"rp0_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rp1_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rp2_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rp3_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rp4_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rp0_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rp1_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rp2_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rp3_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rp4_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rt0_topic\",IntegerType(),true),\n",
    "                     StructField(\"rt1_topic\",IntegerType(),true),\n",
    "                     StructField(\"rt2_topic\",IntegerType(),true),\n",
    "                     StructField(\"rt3_topic\",IntegerType(),true),\n",
    "                     StructField(\"rt4_topic\",IntegerType(),true),\n",
    "                     StructField(\"rt0_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rt1_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rt2_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rt3_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rt4_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rt0_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rt1_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rt2_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rt3_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rt4_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rtc0_topic\",IntegerType(),true),\n",
    "                     StructField(\"rtc1_topic\",IntegerType(),true),\n",
    "                     StructField(\"rtc2_topic\",IntegerType(),true),\n",
    "                     StructField(\"rtc3_topic\",IntegerType(),true),\n",
    "                     StructField(\"rtc4_topic\",IntegerType(),true),\n",
    "                     StructField(\"rtc0_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rtc1_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rtc2_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rtc3_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rtc4_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"rtc0_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rtc1_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rtc2_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rtc3_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"rtc4_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"lk0_topic\",IntegerType(),true),\n",
    "                     StructField(\"lk1_topic\",IntegerType(),true),\n",
    "                     StructField(\"lk2_topic\",IntegerType(),true),\n",
    "                     StructField(\"lk3_topic\",IntegerType(),true),\n",
    "                     StructField(\"lk4_topic\",IntegerType(),true),\n",
    "                     StructField(\"lk0_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"lk1_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"lk2_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"lk3_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"lk4_topiccount\",DoubleType(),true),\n",
    "                     StructField(\"lk0_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"lk1_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"lk2_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"lk3_topicprop\",DoubleType(),true),\n",
    "                     StructField(\"lk4_topicprop\",DoubleType(),true))])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_processed_schema(has_labels=True):\n",
    "    if has_labels:\n",
    "        schema = StructType([StructField('embedding_ors', StringType()),\n",
    "                             StructField('tweet_id_id', StringType()),\n",
    "                             StructField('engaged_with_user_id_id', StringType()),\n",
    "                             StructField('engaged_with_user_is_verified_bool', BooleanType()),\n",
    "                             StructField('engaging_user_id_id', StringType()),\n",
    "                             StructField('engaging_user_is_verified_bool', BooleanType()),\n",
    "                             StructField('engagee_follows_engager_bool', BooleanType()),\n",
    "                             StructField('hashtagEncoded_unors', StringType()),\n",
    "                             StructField('hashtagSumCount_ss_num', DoubleType()),\n",
    "                             StructField('hashtagCount_ss_num', DoubleType()),\n",
    "                             StructField('domainEncoded_unors', StringType()),\n",
    "                             StructField('domainCount_ss_num', DoubleType()),\n",
    "                             StructField('tweetEncoded_cat', IntegerType()),\n",
    "                             StructField('languageEncoded_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_day_of_week_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_week_of_month_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_hour_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_to_engagee_account_creation_ss_num', DoubleType()),\n",
    "                             StructField('tweet_timestamp_to_engaging_account_creation_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_vs_engaging_follower_diff_log_ss_num', DoubleType()), \n",
    "                             StructField('engaged_with_vs_engaging_following_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_follow_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_follow_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_follower_diff_engaging_following_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_following_diff_engaging_follower_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_follower_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_user_follower_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_following_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_user_following_count_log_ss_num', DoubleType()),\n",
    "                             StructField('PhotoCount_ss_num', DoubleType()),\n",
    "                             StructField('VideoCount_ss_num', DoubleType()),\n",
    "                             StructField('GIFCount_ss_num', DoubleType()),\n",
    "                             StructField('linkCount_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_follower_count_q_cat', DoubleType()),\n",
    "                             StructField('engaged_with_user_following_count_q_cat', DoubleType()),\n",
    "                             StructField('engaged_with_user_account_creation_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_follower_count_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_following_count_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_account_creation_q_cat', DoubleType()),\n",
    "                             StructField('total_appearance_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_interactions_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_commented_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_liked_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_replied_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_retweeted_ss_num', DoubleType()),\n",
    "                             StructField('indicator_reply', IntegerType()),\n",
    "                             StructField('indicator_retweet', IntegerType()),\n",
    "                             StructField('indicator_retweet_with_comment', IntegerType()),\n",
    "                             StructField('indicator_like', IntegerType()),\n",
    "                             StructField('indicator_interaction', IntegerType()),\n",
    "                             StructField('engaged_with_user_id_bucket', IntegerType()),\n",
    "                             StructField('engaging_user_id_bucket', IntegerType()), \n",
    "                             StructField('cluster_cat', LongType())])\n",
    "    else:\n",
    "        schema = StructType([StructField('embedding_ors', StringType()),\n",
    "                         StructField('tweet_id_id', StringType()),\n",
    "                         StructField('engaged_with_user_id_id', StringType()),\n",
    "                         StructField('engaged_with_user_is_verified_bool', BooleanType()),\n",
    "                         StructField('engaging_user_id_id', StringType()),\n",
    "                         StructField('engaging_user_is_verified_bool', BooleanType()),\n",
    "                         StructField('engagee_follows_engager_bool', BooleanType()),\n",
    "                         StructField('hashtagEncoded_unors', StringType()),\n",
    "                         StructField('hashtagSumCount_ss_num', DoubleType()),\n",
    "                         StructField('hashtagCount_ss_num', DoubleType()),\n",
    "                         StructField('domainEncoded_unors', StringType()),\n",
    "                         StructField('domainCount_ss_num', DoubleType()),\n",
    "                         StructField('tweetEncoded_cat', IntegerType()),\n",
    "                         StructField('languageEncoded_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_day_of_week_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_week_of_month_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_hour_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_to_engagee_account_creation_ss_num', DoubleType()),\n",
    "                         StructField('tweet_timestamp_to_engaging_account_creation_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_vs_engaging_follower_diff_log_ss_num', DoubleType()), \n",
    "                         StructField('engaged_with_vs_engaging_following_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_follow_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_follow_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_follower_diff_engaging_following_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_following_diff_engaging_follower_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_follower_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_user_follower_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_following_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_user_following_count_log_ss_num', DoubleType()),\n",
    "                         StructField('PhotoCount_ss_num', DoubleType()),\n",
    "                         StructField('VideoCount_ss_num', DoubleType()),\n",
    "                         StructField('GIFCount_ss_num', DoubleType()),\n",
    "                         StructField('linkCount_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_follower_count_q_cat', DoubleType()),\n",
    "                         StructField('engaged_with_user_following_count_q_cat', DoubleType()),\n",
    "                         StructField('engaged_with_user_account_creation_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_follower_count_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_following_count_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_account_creation_q_cat', DoubleType()),\n",
    "                         StructField('total_appearance_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_interactions_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_commented_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_liked_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_replied_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_retweeted_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_id_bucket', IntegerType()),\n",
    "                         StructField('engaging_user_id_bucket', IntegerType()), \n",
    "                         StructField('cluster_cat', LongType())])\n",
    "    return schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
