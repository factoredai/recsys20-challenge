{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "# Goal\n",
    "Create a data pipeline for twitter challenge.\n",
    "\n",
    "# Methodology\n",
    "Create different features from the original data\n",
    "\n",
    "## Sections\n",
    "1. [**Requirements**](#Requirements)\n",
    "2. [**Functions**](#Functions)\n",
    "3. [**Inputs**](#Inputs)\n",
    "4. [**Pipeline**](#Pipeline)\n",
    "    - [**Indicators**](#Indicators)\n",
    "    - [**Intention_features**](#Intention_features)\n",
    "    - [**TopicEncodings**](#TopicEncodings)\n",
    "    - [**EngagingFollowsEngaged**](#EngagingFollowsEngaged)\n",
    "    - [**Hashtags**](#Hashtags)\n",
    "    - [**Domain**](#Domain)\n",
    "    - [**Language**](#Language)\n",
    "    - [**Media**](#Media)\n",
    "    - [**Links**](#Links)\n",
    "    - [**Tweet_type**](#Tweet_type)\n",
    "    - [**Timestamp_features**](#Timestamp_features)\n",
    "    - [**Followers_and_Followings_features**](#Followers_and_Followings_features)\n",
    "    - [**Quantile_Discretizer**](#Quantile_Discretizer)\n",
    "    - [**Intentions_join**](#Intentions_join)\n",
    "5. [**FeatureSelection**](#FeatureSelection)\n",
    "6. [**Imputation**](#Imputation)\n",
    "7. [**Validation**](#Validation)\n",
    "8. [**Saving_df**](#Saving_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#installing packages\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f301ee24a84efa90705a2e777eff5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reconfiguring SparkContext\n",
    "sc.setCheckpointDir('hdfs:///twitter/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a529daef9c6949c790563ac7ada11c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048M\n",
      "1000"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (FloatType, DateType, StructType, StructField, StringType, LongType, \n",
    "    IntegerType, ArrayType, BooleanType, DoubleType)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, QuantileDiscretizer\n",
    "gc.enable()\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", 1000).appName(\"twitter\").getOrCreate()\n",
    "print(spark.sparkContext.getConf().get('spark.driver.memory'))\n",
    "print(spark.sparkContext.getConf().get(\"spark.sql.shuffle.partitions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc31304dbb144fb8e0d1e007b5eff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_data(path='training.tsv', has_labels=True, schema='auto'):\n",
    "    \"\"\"\n",
    "    Parses the training data for the Twitter RecSys Challenge.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.appName(\"twitter\").getOrCreate()\n",
    "    if schema == 'auto':\n",
    "        schema = build_schema(has_labels)\n",
    "    df = spark.read.csv(path, schema=schema, sep='\\x01', encoding='utf-8',\n",
    "                        ignoreLeadingWhiteSpace=True, ignoreTrailingWhiteSpace=True)\n",
    "    df = df.withColumn('text_tokens', F.split('text_tokens', '\\t'))\n",
    "    df = df.withColumn('hashtags', F.split('hashtags', '\\t'))\n",
    "    df = df.withColumn('present_media', F.split('present_media', '\\t'))\n",
    "    df = df.withColumn('present_links', F.split('present_links', '\\t'))\n",
    "    df = df.withColumn('present_domains', F.split('present_domains', '\\t'))\n",
    "    return df\n",
    "\n",
    "def build_schema(has_labels=True):\n",
    "    if has_labels:\n",
    "        schema = StructType([StructField('text_tokens', StringType()),\n",
    "                             StructField('hashtags', StringType()),\n",
    "                             StructField('tweet_id', StringType()),\n",
    "                             StructField('present_media', StringType()),\n",
    "                             StructField('present_links', StringType()),\n",
    "                             StructField('present_domains', StringType()),\n",
    "                             StructField('tweet_type', StringType()),\n",
    "                             StructField('language', StringType()),\n",
    "                             StructField('tweet_timestamp', LongType()),\n",
    "                             StructField('engaged_with_user_id', StringType()),\n",
    "                             StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                             StructField('engaged_with_user_account_creation', LongType()),\n",
    "                             StructField('engaging_user_id', StringType()),\n",
    "                             StructField('engaging_user_follower_count', IntegerType()),\n",
    "                             StructField('engaging_user_following_count', IntegerType()),\n",
    "                             StructField('engaging_user_is_verified', BooleanType()),\n",
    "                             StructField('engaging_user_account_creation', LongType()),\n",
    "                             StructField('engagee_follows_engager', BooleanType()),\n",
    "                             StructField('reply_timestamp', LongType()),\n",
    "                             StructField('retweet_timestamp', LongType()),\n",
    "                             StructField('retweet_with_comment_timestamp', LongType()),\n",
    "                             StructField('like_timestamp', LongType())\n",
    "                            ])\n",
    "    else:\n",
    "         schema = StructType([StructField('text_tokens', StringType()),\n",
    "                             StructField('hashtags', StringType()),\n",
    "                             StructField('tweet_id', StringType()),\n",
    "                             StructField('present_media', StringType()),\n",
    "                             StructField('present_links', StringType()),\n",
    "                             StructField('present_domains', StringType()),\n",
    "                             StructField('tweet_type', StringType()),\n",
    "                             StructField('language', StringType()),\n",
    "                             StructField('tweet_timestamp', LongType()),\n",
    "                             StructField('engaged_with_user_id', StringType()),\n",
    "                             StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                             StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                             StructField('engaged_with_user_account_creation', LongType()),\n",
    "                             StructField('engaging_user_id', StringType()),\n",
    "                             StructField('engaging_user_follower_count', IntegerType()),\n",
    "                             StructField('engaging_user_following_count', IntegerType()),\n",
    "                             StructField('engaging_user_is_verified', BooleanType()),\n",
    "                             StructField('engaging_user_account_creation', LongType()),\n",
    "                             StructField('engagee_follows_engager', BooleanType())\n",
    "                            ])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f525c2beb8402ebaa9b68de0310db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mediaCounter(row, media='Photo'):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem==media:\n",
    "                counter+=1\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def listCounter(row):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        counter+=len(row)\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def labelEncoder(row, mapping_encode):\n",
    "    \"\"\"\n",
    "    Label Encoding or Array<String> types\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    row : list(string)\n",
    "        List of string or labels\n",
    "    mapping_encode : dict(label, integer)\n",
    "        Encoding of some top K labels\n",
    "    Return:\n",
    "    -------\n",
    "    out : list(integers)\n",
    "        List of Label Encoders.\n",
    "        if not in mapping Encoded to len(map)\n",
    "        if not a list Encoded to len(map)+1\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem in mapping_encode:\n",
    "                out.append(mapping_encode.get(elem))\n",
    "            else:\n",
    "                out.append(len(mapping_encode))\n",
    "    else:\n",
    "        out.append(len(mapping_encode)+1)\n",
    "    return out\n",
    "\n",
    "def labelEncoderSingle(row, mapping_encode):\n",
    "    out=[]\n",
    "    if row:\n",
    "        if row in mapping_encode:\n",
    "            out.append(mapping_encode.get(row))\n",
    "        else:\n",
    "            out.append(len(mapping_encode))\n",
    "    else:\n",
    "        out.append(len(mapping_encode)+1)\n",
    "    return out\n",
    "\n",
    "def hashtagSumCounter(row, mapping_hashtag_count):\n",
    "    counter=0\n",
    "    if type(row)==list:\n",
    "        for elem in row:\n",
    "            if elem in mapping_hashtag_count:\n",
    "                counter+=mapping_hashtag_count.get(elem, 0)\n",
    "    else:\n",
    "        pass\n",
    "    return counter\n",
    "\n",
    "def get_distribution_array_col(df, col):\n",
    "    distribution_df = df.select(col).filter(F.col(col).isNotNull())\\\n",
    "                              .withColumn(col, \n",
    "                                          F.explode(F.col(col)))\\\n",
    "                              .groupBy(col).count()\\\n",
    "                              .orderBy(F.col(\"count\").desc())\n",
    "    return distribution_df\n",
    "\n",
    "def save_pkl_to_s3(obj, key_filename, bucket_name):\n",
    "    serialized_obj = pickle.dumps(obj)\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket_name, Key=key_filename, \n",
    "                  Body=serialized_obj)\n",
    "    \n",
    "def columns2cast(df):\n",
    "    columns = []\n",
    "    for col in df.schema:\n",
    "        if col.dataType.typeName()==\"array\":\n",
    "            columns.append(col)\n",
    "    return columns\n",
    "    \n",
    "def cast_array2string(df, columns):\n",
    "    for col in columns:\n",
    "        df = df.withColumn(col.name, F.col(col.name).cast(StringType()))\n",
    "    return df\n",
    "\n",
    "def cast_string2array(df, columns):\n",
    "    for col in columns:\n",
    "        df= df.withColumn(col, \n",
    "                          F.split(F.regexp_replace(F.col(col), r\"(^\\[)|(\\]$)|(')\", \"\"),\n",
    "                                  \", \"))\n",
    "    return df\n",
    "    \n",
    "def mappings(df, col, top_k):\n",
    "    col_dist = get_distribution_array_col(df, col)\n",
    "    df_col_dist = col_dist.limit(top_k)\n",
    "    df_col = df_col_dist.toPandas().rename(columns={'_1': col, \n",
    "                                                    '_2': 'count'})\\\n",
    "                                    .reset_index().set_index(col)\n",
    "    mapping_encode = df_col['index'].to_dict()\n",
    "    mapping_count = df_col['count'].to_dict()\n",
    "    return mapping_encode, mapping_count\n",
    "\n",
    "def mapping_label_encoder(df, col, top_k):\n",
    "    col_dist = df.select(col).filter(F.col(col).isNotNull())\\\n",
    "                      .groupBy(col).count()\\\n",
    "                      .orderBy(F.col(\"count\").desc())\n",
    "    df_col_dist = col_dist.limit(top_k)\n",
    "    df_col = df_col_dist.toPandas().rename(columns={'_1': col, \n",
    "                                                    '_2': 'count'})\\\n",
    "                                    .reset_index().set_index(col)\n",
    "    mapping_encoder = df_col['index'].to_dict()\n",
    "    return mapping_encoder\n",
    "\n",
    "def validator(df):\n",
    "    columns_w_nan = {}\n",
    "    for col in df.schema:\n",
    "        null_count = df.filter(F.col(col.name).isNull()).count()\n",
    "        if null_count>0:\n",
    "            columns_w_nan[col.name]=null_count\n",
    "    return columns_w_nan\n",
    "\n",
    "# Mappings\n",
    "tweet_type_mapping = {'TopLevel':0, 'Quote':1, 'Retweet':2, 'Reply':3}\n",
    "\n",
    "# UDF SQL\n",
    "PhotoCounter_udf = F.udf(lambda row: mediaCounter(row, 'Photo'), \n",
    "                         IntegerType())\n",
    "VideoCounter_udf = F.udf(lambda row: mediaCounter(row, 'Video'), \n",
    "                         IntegerType())\n",
    "GifCounter_udf = F.udf(lambda row: mediaCounter(row, 'GIF'), \n",
    "                         IntegerType())\n",
    "listCounter_udf = F.udf(listCounter, \n",
    "                         IntegerType())\n",
    "tweet_encoded_udf = F.udf(lambda x: tweet_type_mapping[x], \n",
    "                             IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b723449397b04abc992c72004b89a363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary_size={\"final-complete\": {\"val_size\": 500000, \n",
    "                                    \"train_size\": \"all\"}}\n",
    "\n",
    "training = False\n",
    "submission = False\n",
    "test = True\n",
    "\n",
    "bucket='bucket-name'\n",
    "s3_resource = boto3.resource('s3')\n",
    "top_k_languages = 30\n",
    "top_k_domains = 3000\n",
    "top_k_hashtags = 13000\n",
    "\n",
    "# Embeddings\n",
    "num_partitions=1000\n",
    "\n",
    "# Buckets\n",
    "partition_per_cluster = 100\n",
    "\n",
    "suffix_sample = \"final-complete\" #\"full\", \"small\", \"medium\", \"sub_medium\"\n",
    "data_path = \"final-data\"\n",
    "object_paths = \"final-artifacts\"\n",
    "\n",
    "val_size = dictionary_size[suffix_sample][\"val_size\"]\n",
    "train_size = dictionary_size[suffix_sample][\"train_size\"]\n",
    "\n",
    "bucket_s3 = s3_resource.Bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a683f3122e4e50ad06a4c6d99d69a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#S3\n",
    "twitter_bucket_s3 = \"s3a://bucket-name\"\n",
    "trainining_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"training.tsv\")\n",
    "submission_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"submission.tsv\")\n",
    "test_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"test.tsv\")\n",
    "\n",
    "# Splitted paths\n",
    "train_path = os.path.join(twitter_bucket_s3, data_path, \"train-\"+suffix_sample)\n",
    "val_path = os.path.join(twitter_bucket_s3, data_path, \"val-\"+suffix_sample)\n",
    "\n",
    "# Processed\n",
    "processed_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"train-\"+suffix_sample)\n",
    "processed_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"val-\"+suffix_sample)\n",
    "processed_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"submission-\"+suffix_sample)\n",
    "processed_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"test-\"+suffix_sample)\n",
    "processed_emb_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_emb_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_emb_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"submission-\"+suffix_sample)\n",
    "processed_emb_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"test-\"+suffix_sample)\n",
    "processed_top_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_top_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_top_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"submission-\"+suffix_sample)\n",
    "processed_top_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"test-\"+suffix_sample)\n",
    "# Resources\n",
    "engaging_users_training_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-training\")\n",
    "engaging_users_submission_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-submission\")\n",
    "engaging_users_test_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-test\")\n",
    "intentions_path = os.path.join(twitter_bucket_s3, data_path, \"intentions-\"+suffix_sample)\n",
    "map_user_bucket_path = os.path.join(twitter_bucket_s3, data_path, \"map_user_bucket\")\n",
    "\n",
    "topic_encodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"user_topics\")\n",
    "users_intime_path = os.path.join(twitter_bucket_s3, data_path, \"users_intime-\"+suffix_sample)\n",
    "\n",
    "# keys objects\n",
    "key_hashtag_mapping = os.path.join(object_paths, f'hashtag_mapping_{suffix_sample}.pkl')\n",
    "key_domain_mapping = os.path.join(object_paths, f'domain_mapping_{suffix_sample}.pkl')\n",
    "key_language_mapping = os.path.join(object_paths, f'language_mapping_{suffix_sample}.pkl')\n",
    "key_hashtag_count = os.path.join(object_paths, f'hashtag_count_{suffix_sample}.pkl')\n",
    "key_domain_count = os.path.join(object_paths, f'domain_count_{suffix_sample}.pkl')\n",
    "key_scaling_features = os.path.join(object_paths, f'scaling_dictionary_{suffix_sample}.pkl')\n",
    "key_diff_min = os.path.join(object_paths, f'diff_min_{suffix_sample}.pkl')\n",
    "key_impute_perc = os.path.join(object_paths, f'dict_mean_perc_{suffix_sample}.pkl')\n",
    "key_topiccount = os.path.join(object_paths, f'topiccount_{suffix_sample}.pkl')\n",
    "\n",
    "# s3+keys\n",
    "columns = [\"engaged_with_user_follower_count\", \"engaged_with_user_following_count\",\n",
    "           \"engaged_with_user_account_creation\", \"engaging_user_follower_count\",\n",
    "           \"engaging_user_following_count\", \"engaging_user_account_creation\"]\n",
    "qds_paths = {}\n",
    "for col in columns:\n",
    "    qds_paths[col] = os.path.join(twitter_bucket_s3, object_paths, f\"qs_{suffix_sample}_\" + col)\n",
    "    \n",
    "# Bucket pipeline\n",
    "users_buckets = os.path.join(twitter_bucket_s3, data_path, \"users_buckets\") #\n",
    "users_buckets_part_2 = os.path.join(twitter_bucket_s3, data_path, \"users_buckets_part_2\") #\n",
    "\n",
    "pipeline_kmeans_path = os.path.join(twitter_bucket_s3, object_paths, \"pipeline_id_encoding\")\n",
    "cluster_map_path = os.path.join(twitter_bucket_s3, data_path, \"cluster_map\")\n",
    "\n",
    "# Embeddings\n",
    "bert_embeddings_train = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"tweets_extended\")\n",
    "submission_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"submission-tweets-extended\")\n",
    "test_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"test-tweets-extended\")\n",
    "\n",
    "# Topics pipeline\n",
    "reduced_topics_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"reducedTopics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engaging-users-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e50cfb0dc475fa6b736b21fb03620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/engaging-users-training\", Delimiter='./')))==0:\n",
    "    df = parse_data(trainining_path, has_labels=True).repartition(500)\n",
    "    engaging_user_id_train = df.select(\"engaging_user_id\").distinct()\n",
    "    engaging_user_id_train.write.csv(engaging_users_training_path)\n",
    "\n",
    "engaging_users_train = spark.read.csv(engaging_users_training_path, \n",
    "                                      schema=StructType([StructField('engaging_user_id', StringType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac794e07e5f433d82ecb07b2dbd7b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submission\n",
    "if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/engaging-users-submission\", Delimiter='./')))==0:\n",
    "    df = parse_data(submission_path, has_labels=False).repartition(200)\n",
    "    engaging_users_submission = df.select(\"engaging_user_id\").distinct()\n",
    "    engaging_users_submission.write.csv(engaging_users_submission_path)\n",
    "\n",
    "engaging_users_submission = spark.read.csv(engaging_users_submission_path, \n",
    "                                    schema=StructType([StructField('engaging_user_id', StringType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51968da9121e4d20be569a06fe923628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/engaging-users-test\", Delimiter='./')))==0:\n",
    "    df = parse_data(test_path, has_labels=False).repartition(200)\n",
    "    engaging_users_test = df.select(\"engaging_user_id\").distinct()\n",
    "    engaging_users_test.write.csv(engaging_users_test_path)\n",
    "\n",
    "engaging_users_test = spark.read.csv(engaging_users_test_path, \n",
    "                                    schema=StructType([StructField('engaging_user_id', StringType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc47f8a19f4947b30ab71652b422af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    df = parse_data(submission_path, has_labels=False).repartition(300)\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    df = parse_data(test_path, has_labels=False).repartition(300)\n",
    "else:\n",
    "    print(\"Train\")\n",
    "    df = parse_data(trainining_path, has_labels=True).repartition(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839e1d87366644cabf92bb466956232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_final_df(df, time_holdout_fraction=0.1, space_column='engaging_user_id', \n",
    "                   time_column='tweet_timestamp', avg_rows_per_user=5.4, \n",
    "                   val_size = 500000, perc_val_not_shared = 0.27, seed=0, \n",
    "                   engaging_users_submission=None, engaging_users_test=None):\n",
    "    \"\"\"\n",
    "    Split using all the train data.\n",
    "    Exclude all engaging_users from submission and test to create the validation\n",
    "    Select the validatioon to be up to 500k samples, where 23% of enagging users are not known \n",
    "    (out of space completely). The validation is going to be picked out of time, but the rest \n",
    "    of out of time is gooing ot be used in train\n",
    "    \"\"\"\n",
    "    info_dict = {}\n",
    "    min_date, max_date = df.select(F.min(time_column), F.max(time_column)).first()\n",
    "    time_range = max_date - min_date\n",
    "    time_holdout_timestamp = min_date + int(time_range*(1-time_holdout_fraction))\n",
    "\n",
    "    #Get engaging_users on submission and test\n",
    "    engaging_users_test = engaging_users_submission.union(engaging_users_test)\n",
    "    engaging_users_test = engaging_users_test.select(F.col(\"engaging_user_id\").alias(\"user_id_1\")).distinct()\n",
    "\n",
    "    join_users_df = engaging_users_train.join(engaging_users_test, \n",
    "                                              engaging_users_test.user_id_1==engaging_users_train.engaging_user_id, \n",
    "                                              how=\"left\")\n",
    "    join_users_df = join_users_df.withColumn(\"indicator_test\", \n",
    "                                             F.when(F.col(\"user_id_1\").isNotNull(), 1).otherwise(0))\n",
    "    join_users_df = join_users_df.drop(\"user_id_1\") # Training user w indicator also in test\n",
    "    join_users_not_test = join_users_df.filter(F.col(\"indicator_test\")==0)\n",
    "    \n",
    "    # Sample that are not in test\n",
    "    df_not_test = df.join(join_users_not_test,\n",
    "                          on=space_column, \n",
    "                          how=\"inner\")\n",
    "    df_not_test = df_not_test.drop(\"indicator_test\")\n",
    "    info_dict[\"df_not_test_count\"] = df_not_test.count()\n",
    "\n",
    "    df_not_test_intime = df_not_test.filter(F.col(time_column) <= time_holdout_timestamp)\n",
    "    df_not_test_outtime = df_not_test.filter(F.col(time_column) > time_holdout_timestamp) # Set for validation\n",
    "    info_dict[\"df_not_test_intime_count\"] = df_not_test_intime.count() #\n",
    "    info_dict[\"df_not_test_outtime_count\"] = df_not_test_outtime.count() #\n",
    "    engaging_user_id_intime_not_test = df_not_test_intime.select(F.col(space_column)).distinct()\n",
    "    engaging_user_id_outtime_not_test = df_not_test_outtime.select(F.col(space_column)).distinct()\n",
    "    info_dict[\"engaging_user_id_intime_not_test_count\"] = engaging_user_id_intime_not_test.count() #\n",
    "    info_dict[\"engaging_user_id_outtime_not_test_count\"] = engaging_user_id_outtime_not_test.count() #\n",
    "    inner_engaging_not_test = engaging_user_id_intime_not_test.join(engaging_user_id_outtime_not_test, \n",
    "                                                                    on=space_column, \n",
    "                                                                    how=\"inner\")\n",
    "    info_dict[\"inner_engaging_not_test_count\"] = inner_engaging_not_test.count() #\n",
    "    rows_per_user_outtime_not_test = info_dict[\"df_not_test_outtime_count\"]/\\\n",
    "                                      info_dict[\"engaging_user_id_outtime_not_test_count\"]\n",
    "    \n",
    "    engaging_user_id_only_outtime_not_test =engaging_user_id_outtime_not_test.join(inner_engaging_not_test,\n",
    "                                                                                   on=space_column,\n",
    "                                                                                   how=\"left_anti\")\n",
    "    info_dict[\"engaging_user_id_only_outtime_not_test_count\"] = engaging_user_id_only_outtime_not_test.count()#\n",
    "    frac_user_only_outtime = val_size/rows_per_user_outtime_not_test*(perc_val_not_shared)\\\n",
    "                        /info_dict[\"engaging_user_id_only_outtime_not_test_count\"] # Validation shared \n",
    "    valid_users_not_test_outtime = engaging_user_id_only_outtime_not_test.sample(withReplacement=False,\n",
    "                                                                           fraction=frac_user_only_outtime,\n",
    "                                                                           seed=seed)\n",
    "    valid_users_not_test_outtime = valid_users_not_test_outtime.select(F.col(\"engaging_user_id\").alias(\"user_id\"))\n",
    "\n",
    "    # Select the sample from that correspnd to 27% of rows\n",
    "    df_valid_unknown = df_not_test_outtime.join(valid_users_not_test_outtime, \n",
    "                                    df_not_test_outtime.engaging_user_id==valid_users_not_test_outtime.user_id,\n",
    "                                    how=\"inner\").drop(\"user_id\")\n",
    "    \n",
    "    #Select the rest\n",
    "    frac_user_inner = val_size/rows_per_user_outtime_not_test*(1-perc_val_not_shared)\\\n",
    "                        /info_dict[\"inner_engaging_not_test_count\"] # Validation shared \n",
    "    inner_engaging_not_test = inner_engaging_not_test.select(F.col(\"engaging_user_id\").alias(\"user_id\"))\n",
    "    valid_users_not_test_shared = inner_engaging_not_test.sample(withReplacement=False,\n",
    "                                                                 fraction=frac_user_inner,\n",
    "                                                                 seed=seed)\n",
    "    df_valid_known = df_not_test_outtime.join(valid_users_not_test_shared,\n",
    "                                    df_not_test_outtime.engaging_user_id==inner_engaging_not_test.user_id,\n",
    "                                    how=\"inner\").drop(\"user_id\")\n",
    "    df_valid = df_valid_known.union(df_valid_unknown)\n",
    "\n",
    "    valid_samples = df_valid.select(F.col(\"tweet_id\").alias(\"tweet_id_1\"), \n",
    "                                    F.col(\"engaging_user_id\").alias(\"engaging_user_id_1\"))\n",
    "    df_train = df.join(valid_samples, \n",
    "                       (df.tweet_id==valid_samples.tweet_id_1)&\\\n",
    "                       (df.engaging_user_id == valid_samples.engaging_user_id_1), \n",
    "                       how=\"left_anti\")\n",
    "    return df_train, df_valid, join_users_not_test, info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bc34199eb9481b95ed2c2654df090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists"
     ]
    }
   ],
   "source": [
    "if not(submission):\n",
    "    if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/train-\"+suffix_sample, Delimiter='./')))==0:\n",
    "        df_train, df_valid, join_users_not_test, info_dict = split_final_df(df, time_holdout_fraction=0.1, \n",
    "                                                               space_column='engaging_user_id', \n",
    "                                                               time_column='tweet_timestamp',\n",
    "                                                               avg_rows_per_user=5.4, val_size=val_size, \n",
    "                                                               perc_val_not_shared=0.27, seed=0, \n",
    "                                                               engaging_users_submission=engaging_users_submission, \n",
    "                                                               engaging_users_test=engaging_users_test)\n",
    "        print(\"info_dict: \", info_dict)\n",
    "        train = df_train\n",
    "        val = df_valid\n",
    "        columns = columns2cast(train)\n",
    "        train = cast_array2string(train, columns)\n",
    "        val = cast_array2string(val, columns)\n",
    "        join_users_not_test.write.csv(users_intime_path)\n",
    "        train.write.csv(train_path)\n",
    "        val.repartition(1000).write.csv(val_path)\n",
    "        print(\"Casted columns: \",columns)\n",
    "    else:\n",
    "        print(\"Already exists\")\n",
    "schema = StructType([StructField('text_tokens', StringType()),\n",
    "                     StructField('hashtags', StringType()),\n",
    "                     StructField('tweet_id', StringType()),\n",
    "                     StructField('present_media', StringType()),\n",
    "                     StructField('present_links', StringType()),\n",
    "                     StructField('present_domains', StringType()),\n",
    "                     StructField('tweet_type', StringType()),\n",
    "                     StructField('language', StringType()),\n",
    "                     StructField('tweet_timestamp', LongType()),\n",
    "                     StructField('engaged_with_user_id', StringType()),\n",
    "                     StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                     StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                     StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                     StructField('engaged_with_user_account_creation', LongType()),\n",
    "                     StructField('engaging_user_id', StringType()),\n",
    "                     StructField('engaging_user_follower_count', IntegerType()),\n",
    "                     StructField('engaging_user_following_count', IntegerType()),\n",
    "                     StructField('engaging_user_is_verified', BooleanType()),\n",
    "                     StructField('engaging_user_account_creation', LongType()),\n",
    "                     StructField('engagee_follows_engager', BooleanType()),\n",
    "                     StructField('reply_timestamp', LongType()),\n",
    "                     StructField('retweet_timestamp', LongType()),\n",
    "                     StructField('retweet_with_comment_timestamp', LongType()),\n",
    "                     StructField('like_timestamp', LongType())])\n",
    "train = spark.read.csv(train_path, schema=schema)\n",
    "schema = StructType([StructField('engaging_user_id', StringType()),\n",
    "                     StructField('text_tokens', StringType()),\n",
    "                     StructField('hashtags', StringType()),\n",
    "                     StructField('tweet_id', StringType()),\n",
    "                     StructField('present_media', StringType()),\n",
    "                     StructField('present_links', StringType()),\n",
    "                     StructField('present_domains', StringType()),\n",
    "                     StructField('tweet_type', StringType()),\n",
    "                     StructField('language', StringType()),\n",
    "                     StructField('tweet_timestamp', LongType()),\n",
    "                     StructField('engaged_with_user_id', StringType()),\n",
    "                     StructField('engaged_with_user_follower_count', IntegerType()),\n",
    "                     StructField('engaged_with_user_following_count', IntegerType()),\n",
    "                     StructField('engaged_with_user_is_verified', BooleanType()),\n",
    "                     StructField('engaged_with_user_account_creation', LongType()),\n",
    "                     StructField('engaging_user_follower_count', IntegerType()),\n",
    "                     StructField('engaging_user_following_count', IntegerType()),\n",
    "                     StructField('engaging_user_is_verified', BooleanType()),\n",
    "                     StructField('engaging_user_account_creation', LongType()),\n",
    "                     StructField('engagee_follows_engager', BooleanType()),\n",
    "                     StructField('reply_timestamp', LongType()),\n",
    "                     StructField('retweet_timestamp', LongType()),\n",
    "                     StructField('retweet_with_comment_timestamp', LongType()),\n",
    "                     StructField('like_timestamp', LongType())])\n",
    "val = spark.read.csv(val_path, schema=schema).repartition(1000)\n",
    "join_users_not_test = spark.read.csv(users_intime_path, \n",
    "                              schema=StructType([StructField('engaging_user_id', StringType())]))\n",
    "columns = [\"text_tokens\", \"hashtags\", \"present_media\", \"present_links\", \"present_domains\"]\n",
    "train = cast_string2array(train, columns)\n",
    "val = cast_string2array(val, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2124a2196218409c9cdf1db7638b21b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "else:\n",
    "    if training:\n",
    "        print(\"Train\")\n",
    "        df = train\n",
    "    else:\n",
    "        print(\"Validation\")\n",
    "        df = val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8840e7a24e41aeae1279f3ec5be75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12434838"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad173690fc20425d98abe262e22148b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': 9802258, 'present_media': 7855555, 'present_links': 10560235, 'present_domains': 10560235}"
     ]
    }
   ],
   "source": [
    "columns_w_nan = validator(df)\n",
    "print(columns_w_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac46ee7dd23e4f48ab8de604f42d0459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not(submission) and not(test):\n",
    "    df = df.withColumn('indicator_reply',F.when(F.col('reply_timestamp').isNotNull(), 1).otherwise(0))\n",
    "    df = df.withColumn('indicator_retweet',F.when(F.col('retweet_timestamp').isNotNull(), 1).otherwise(0))\n",
    "    df = df.withColumn('indicator_retweet_with_comment',\n",
    "                       F.when(F.col('retweet_with_comment_timestamp').isNotNull(),1).otherwise(0))\n",
    "    df = df.withColumn('indicator_like', F.when(F.col('like_timestamp').isNotNull(),1).otherwise(0))\n",
    "    df = df.withColumn('indicator_interaction', \n",
    "                       F.when(F.col('indicator_reply')+\\\n",
    "                              F.col('indicator_retweet')+\\\n",
    "                              F.col('indicator_retweet_with_comment')+\\\n",
    "                              F.col('indicator_like')>0, 1)\\\n",
    "                       .otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intention_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0adb881de994db2ace45a20a2b85777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    if len(list(bucket_s3.objects.filter(Prefix=f\"{data_path}/intentions-\"+suffix_sample, Delimiter='./')))==0:\n",
    "        print(\"Creating Intention\")\n",
    "        intention_df = df.select(\"engaging_user_id\", \"indicator_reply\", \"indicator_retweet\", \n",
    "                                    \"indicator_retweet_with_comment\", \"indicator_like\", \"indicator_interaction\")\\\n",
    "                        .groupBy(\"engaging_user_id\").agg(F.sum(F.col(\"indicator_interaction\")).alias(\"n_interactions\"), \n",
    "                                                         F.sum(F.col(\"indicator_retweet_with_comment\"))\\\n",
    "                                                         .alias(\"n_commented\"),\n",
    "                                                         F.sum(F.col(\"indicator_like\")).alias(\"n_liked\"),\n",
    "                                                         F.sum(F.col(\"indicator_reply\")).alias(\"n_replied\"),\n",
    "                                                         F.sum(F.col(\"indicator_retweet\")).alias(\"n_retweeted\"),\n",
    "                                                         F.count(F.col(\"indicator_interaction\"))\\\n",
    "                                                         .alias(\"total_appearance\"))\n",
    "        columns = ['n_interactions', 'n_commented', 'n_liked', 'n_replied', 'n_retweeted']\n",
    "        for col_i in columns:\n",
    "            intention_df = intention_df.withColumn(\"perc_\" + col_i, F.col(col_i)/(F.col(\"total_appearance\")))\n",
    "        intention_df = intention_df.drop(*columns)\n",
    "        join_users_not_test = join_users_not_test.select(F.col(\"engaging_user_id\").alias(\"drop_users\"))\n",
    "        join_users_not_test = join_users_not_test.sample(withReplacement=False,\n",
    "                                                         fraction=0.15,\n",
    "                                                         seed=42)\n",
    "        intention_df = intention_df.join(join_users_not_test, \n",
    "                                         intention_df.engaging_user_id==join_users_not_test.drop_users, \n",
    "                                         how=\"left_anti\").drop(\"drop_users\")\n",
    "        intention_df.repartition(1000).write.csv(intentions_path)\n",
    "    else:\n",
    "        print(\"Intention already created\")\n",
    "schema = StructType([StructField('engaging_user_id', StringType()),\n",
    "             StructField('total_appearance', LongType()),\n",
    "             StructField('perc_n_interactions', DoubleType()),\n",
    "             StructField('perc_n_commented', DoubleType()),\n",
    "             StructField('perc_n_liked', DoubleType()),\n",
    "             StructField('perc_n_replied', DoubleType()),\n",
    "             StructField('perc_n_retweeted', DoubleType())])\n",
    "intention_df = spark.read.csv(intentions_path, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5369efd8a0c842b7b48ab664680c1298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating hashtags features\")\n",
    "    mapping_hashtag_encode, mapping_hashtag_count = mappings(df, \"hashtags\", top_k_hashtags)\n",
    "    # Saving pkl\n",
    "    save_pkl_to_s3(mapping_hashtag_encode, key_hashtag_mapping, bucket)\n",
    "    save_pkl_to_s3(mapping_hashtag_count, key_hashtag_count, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_hashtag_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_hashtag_mapping).get()['Body'].read())\n",
    "mapping_hashtag_count = pickle.loads(s3_resource.Bucket(bucket).Object(key_hashtag_count).get()['Body'].read())\n",
    "        \n",
    "hashtagsEncoder_udf = F.udf(lambda x: labelEncoder(x, mapping_hashtag_encode), \n",
    "                         StringType())\n",
    "df = df.withColumn('hashtagEncoded', hashtagsEncoder_udf(df.hashtags))\n",
    "hashtagSumCounter_udf = F.udf(lambda x: hashtagSumCounter(x, mapping_hashtag_count), \n",
    "                             IntegerType())\n",
    "df = df.withColumn('hashtagSumCount', hashtagSumCounter_udf(df['hashtags']))\n",
    "df = df.withColumn('hashtagCount', listCounter_udf(df.hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a285e79a64a2ba3e75816d1359c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating domains features\")\n",
    "    mapping_domain_encode, mapping_domain_count = mappings(df, \"present_domains\", top_k_domains)\n",
    "    # Saving pkl\n",
    "    save_pkl_to_s3(mapping_domain_encode, key_domain_mapping, bucket)\n",
    "    save_pkl_to_s3(mapping_domain_count, key_domain_count, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_domain_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_domain_mapping).get()['Body'].read())\n",
    "\n",
    "domainEncoder_udf = F.udf(lambda x: labelEncoder(x, mapping_domain_encode), \n",
    "                         StringType())\n",
    "df = df.withColumn('domainEncoded', domainEncoder_udf(df.present_domains))\n",
    "df = df.withColumn('domainCount', listCounter_udf(df.present_domains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143a9fa2cad843169569e418c8b284f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    print(\"Creating language features\")\n",
    "    mapping_encoder = mapping_label_encoder(df, \"language\", top_k_languages)\n",
    "    save_pkl_to_s3(mapping_encoder, key_language_mapping, bucket)\n",
    "\n",
    "# Load dict mapping language\n",
    "mapping_language_encode = pickle.loads(s3_resource.Bucket(bucket).Object(key_language_mapping).get()['Body'].read())\n",
    "        \n",
    "languageEncoder_udf = F.udf(lambda x: labelEncoderSingle(x, mapping_language_encode)[0], \n",
    "                         StringType())\n",
    "df = df.withColumn('languageEncoded', languageEncoder_udf(df.language))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b663aa1e7cd4515bc43e8c080a9f5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_media_counter={'PhotoCount': PhotoCounter_udf,\n",
    "                    'VideoCount': VideoCounter_udf, \n",
    "                    'GIFCount': GifCounter_udf}\n",
    "for media, media_fun in dict_media_counter.items():\n",
    "    df = df.withColumn(media, media_fun(df.present_media))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfda37082e5406e981e84522dd60e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('linkCount', listCounter_udf(df.present_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6aaed1137df4df2b6b630ac53886218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('tweetEncoded', tweet_encoded_udf(df.tweet_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acfb520708947b4b7c9d6a66f9bf1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp_feats = [i for i in df.columns if (('timestamp' in i) or ('creation' in i))]\n",
    "\n",
    "# Timestamp to dates\n",
    "for col_ts in timestamp_feats:\n",
    "    # Taking only the preffix of each column\n",
    "    preffix = col_ts.split(\"_timestamp\")[0]\n",
    "    df = df.withColumn(preffix + \"_date\", F.from_unixtime(col_ts, 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# From tweet_date extracting day of week, week of month and hour of tweet\n",
    "df = df.withColumn( 'tweet_timestamp_day_of_week', F.date_format(F.col('tweet_date'), 'u') )\n",
    "df = df.withColumn( 'tweet_timestamp_week_of_month',  F.date_format(F.col('tweet_date'), \"W\" ) )\n",
    "df = df.withColumn( 'tweet_timestamp_hour',  F.date_format(F.col('tweet_date'), \"H\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling_features\n",
    "As standard scaling will be done manually, we have to create some dictionaries to save the information of the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3107d2964c4abead6e8beaea315a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training: \n",
    "    scaling_dict = dict()\n",
    "else:\n",
    "    scaling_dict = pickle.loads(s3_resource.Bucket(bucket).Object(key_scaling_features).get()['Body'].read())\n",
    "    assert type(scaling_dict) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329b47bf600a475c89dde6ebd5ec2de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Seconds from engagee account creation to tweet posting\n",
    "# Differences of timestamps return a result inv Seconds\n",
    "df = df.withColumn( 'tweet_timestamp_to_engagee_account_creation',  \n",
    "                   F.col('tweet_timestamp') - F.col('engaged_with_user_account_creation'))\n",
    "if training: \n",
    "    mean_col, sttdev_col = df.select(F.mean('tweet_timestamp_to_engagee_account_creation'),\n",
    "                                     F.stddev('tweet_timestamp_to_engagee_account_creation')).first()\n",
    "    # Saving scaling features\n",
    "    scaling_dict['tweet_timestamp_to_engagee_account_creation'] = { 'mean': mean_col, 'std': sttdev_col}    \n",
    "mean_col = scaling_dict['tweet_timestamp_to_engagee_account_creation']['mean']    \n",
    "sttdev_col = scaling_dict['tweet_timestamp_to_engagee_account_creation']['std']\n",
    "    \n",
    "df = df.withColumn('tweet_timestamp_to_engagee_account_creation'+'_ss', \n",
    "                   (F.col('tweet_timestamp_to_engagee_account_creation') - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b2d70a9d74f82bc0616e1fc3306aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Seconds from engaging account creation to tweet posting\n",
    "# Differences of timestamps return a result inv Seconds\n",
    "df = df.withColumn( 'tweet_timestamp_to_engaging_account_creation',  \n",
    "                   F.col('tweet_timestamp') - F.col('engaging_user_account_creation'))\n",
    "#Scaling\n",
    "if training: \n",
    "    mean_col, sttdev_col = df.select(F.mean('tweet_timestamp_to_engaging_account_creation'), \n",
    "                                     F.stddev('tweet_timestamp_to_engaging_account_creation')).first()\n",
    "    # Saving scaling features\n",
    "    scaling_dict['tweet_timestamp_to_engaging_account_creation'] = { 'mean': mean_col, 'std': sttdev_col}    \n",
    "mean_col = scaling_dict['tweet_timestamp_to_engaging_account_creation']['mean']    \n",
    "sttdev_col = scaling_dict['tweet_timestamp_to_engaging_account_creation']['std']\n",
    "\n",
    "df = df.withColumn('tweet_timestamp_to_engaging_account_creation'+'_ss', \n",
    "                   (F.col('tweet_timestamp_to_engaging_account_creation') - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Followers_and_Followings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bb3bede402458297ddd6f1871662fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('engaged_with_vs_engaging_follower_diff',\n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaging_user_follower_count'))\n",
    "df = df.withColumn('engaged_with_vs_engaging_following_diff', \n",
    "                   F.col('engaged_with_user_following_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_follow_diff',\n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaged_with_user_following_count'))\n",
    "df = df.withColumn('engaging_follow_diff', \n",
    "                   F.col('engaging_user_follower_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_follower_diff_engaging_following', \n",
    "                   F.col('engaged_with_user_follower_count') - F.col('engaging_user_following_count'))\n",
    "df = df.withColumn('engaged_following_diff_engaging_follower', \n",
    "                   F.col('engaged_with_user_following_count') - F.col('engaging_user_follower_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5374fa232f3423c80850b7c5a33edd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"engaged_with_vs_engaging_follower_diff\", \"engaged_with_vs_engaging_following_diff\", \n",
    "           \"engaged_follow_diff\", \"engaging_follow_diff\", \"engaged_follower_diff_engaging_following\", \n",
    "           \"engaged_following_diff_engaging_follower\"]\n",
    "if training:\n",
    "    diff_min_dict = {}\n",
    "    for col in columns:\n",
    "        diff_min_dict[col] = df.select(F.min(col)).first()[0]\n",
    "    save_pkl_to_s3(diff_min_dict, key_diff_min, bucket)\n",
    "        \n",
    "diff_min_dict = pickle.loads(s3_resource.Bucket(bucket).Object(key_diff_min).get()['Body'].read())\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.col(col)-diff_min_dict[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log and Standard Scaling of followers and difference features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8588a162273c4ee38adc9c2e7b2ddbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Followers/following counts and differences will transformed to logarithm. We are choosing the column names.\n",
    "columns_to_log = ['engaged_with_vs_engaging_follower_diff', 'engaged_with_vs_engaging_following_diff', \n",
    "                    'engaged_follow_diff', 'engaging_follow_diff', \n",
    "                    'engaged_follower_diff_engaging_following', 'engaged_following_diff_engaging_follower', \n",
    "                    'engaged_with_user_follower_count', 'engaging_user_follower_count', \n",
    "                    'engaged_with_user_following_count', 'engaging_user_following_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a624736ac68443284c5e38162637eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in columns_to_log:\n",
    "    df = df.withColumn(column + '_log', F.log(F.col(column)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6740a511108d4df084898722dab567c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_to_scale = [column for column in df.columns if ('_log' in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02deee6bd644e40951a5e54054e040d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    for col in cols_to_scale:\n",
    "        mean_col, sttdev_col = df.select(F.mean(col), F.stddev(col)).first()\n",
    "        scaling_dict[col] = { 'mean': mean_col, 'std': sttdev_col}\n",
    "\n",
    "for col in cols_to_scale:\n",
    "    mean_col = scaling_dict[col]['mean']\n",
    "    sttdev_col = scaling_dict[col]['std']\n",
    "    df = df.withColumn(col+'_ss', (F.col(col) - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile_Discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bdaea1ea544aab9ead4351b63d65be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training:\n",
    "    qds_obj = {}\n",
    "    qds_paths\n",
    "    for col in qds_paths.keys():\n",
    "        qds = QuantileDiscretizer(numBuckets=50, inputCol=col, outputCol=col+\"_q\")\n",
    "        qds = qds.fit(df)\n",
    "        qds.save(qds_paths[col])\n",
    "        \n",
    "for col in qds_paths.keys():\n",
    "    qds = QuantileDiscretizer.load(qds_paths[col])\n",
    "    df = qds.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentions_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d986237c931c4b40b8f78b768458f620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.join(intention_df, \n",
    "             on=\"engaging_user_id\", \n",
    "             how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dd72435faf4892afea67ed982c8ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"perc_n_interactions\", 'perc_n_commented', 'perc_n_liked', 'perc_n_replied', 'perc_n_retweeted']\n",
    "if training:\n",
    "    dict_mean_perc = {}\n",
    "    for col in columns:\n",
    "        dict_mean_perc[col] = intention_df.select(F.mean(col)).first()[0]\n",
    "    save_pkl_to_s3(dict_mean_perc, key_impute_perc, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa256e00c5f94c8ea1a4125fcaec6fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols_to_scale = [\"hashtagSumCount\", \"hashtagCount\",\n",
    "                     \"domainCount\", \"PhotoCount\",\n",
    "                     \"VideoCount\", \"GIFCount\",\n",
    "                     \"linkCount\", \"total_appearance\",\n",
    "                     \"perc_n_interactions\",\n",
    "                     \"perc_n_commented\",\n",
    "                     \"perc_n_liked\",\n",
    "                     \"perc_n_replied\",\n",
    "                     \"perc_n_retweeted\"]\n",
    "#Scaling\n",
    "if training:\n",
    "    for col in num_cols_to_scale:\n",
    "        mean_col, sttdev_col = df.select(F.mean(col), F.stddev(col)).first()\n",
    "        scaling_dict[col] = {'mean': mean_col, 'std': sttdev_col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DiffsImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6dbfbd37c43a2ae83399211f28187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = ['engaged_with_vs_engaging_follower_diff_log_ss', \n",
    "           'engaged_with_vs_engaging_following_diff_log_ss', \n",
    "           'engaged_follow_diff_log_ss', \n",
    "           'engaging_follow_diff_log_ss', \n",
    "           'engaged_follower_diff_engaging_following_log_ss', \n",
    "           'engaged_following_diff_engaging_follower_log_ss']\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col)).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IntentionsImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2606ec1c3b404f5189e8f3ccdefd95d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.withColumn('total_appearance', F.when(F.col(\"total_appearance\").isNotNull(), \n",
    "                                                   F.col(\"total_appearance\"))\\\n",
    "                          .otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a93ecf829b54deba41b7de9563a4f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\"perc_n_interactions\", 'perc_n_commented', 'perc_n_liked', 'perc_n_replied', 'perc_n_retweeted']\n",
    "        \n",
    "dict_mean_perc = pickle.loads(s3_resource.Bucket(bucket).Object(key_impute_perc).get()['Body'].read())\n",
    "for col in columns:\n",
    "    df = df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col))\\\n",
    "                       .otherwise(dict_mean_perc[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling after imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadd90e4bd134758b9db04332f7f9069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in num_cols_to_scale:\n",
    "    mean_col = scaling_dict[col]['mean']\n",
    "    sttdev_col = scaling_dict[col]['std']\n",
    "    df = df.withColumn(col+'_ss', (F.col(col) - mean_col) / (2*sttdev_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef42af51a5437abf368d81399f191a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deviations_to_clip = 5.0\n",
    "for col in num_cols_to_scale:\n",
    "    df = df.withColumn(col+'_ss', F.when(F.abs(F.col(col+'_ss'))<5, \n",
    "                                         F.col(col+'_ss'))\\\n",
    "                       .otherwise(deviations_to_clip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving scaling_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7356cf5d2544c2197e655dcde488a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training: \n",
    "    # Saving scaling dictionary to pickle\n",
    "    save_pkl_to_s3(scaling_dict, key_scaling_features, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb6556f96a745f0a9d69a294d0f9ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original = ['text_tokens', 'tweet_id', 'engaged_with_user_id', 'engaged_with_user_is_verified',\n",
    "            'engaging_user_id', 'engaging_user_is_verified', 'engagee_follows_engager']\n",
    "\n",
    "processed = ['hashtagEncoded', 'hashtagSumCount_ss', 'hashtagCount_ss', #hashtags\n",
    "             'domainEncoded', 'domainCount_ss', #domains\n",
    "             'tweetEncoded', # tweet type encoded\n",
    "             'languageEncoded',# language encoded\n",
    "             'tweet_timestamp_day_of_week', 'tweet_timestamp_week_of_month', 'tweet_timestamp_hour', #tweet timestamp\n",
    "             'tweet_timestamp_to_engagee_account_creation_ss', #engagee time in twitter proxy\n",
    "             'tweet_timestamp_to_engaging_account_creation_ss', #engaging time in twitter proxy\n",
    "             'engaged_with_vs_engaging_follower_diff_log_ss', #followers engaged\n",
    "             'engaged_with_vs_engaging_following_diff_log_ss', #followings engaged\n",
    "             'engaged_follow_diff_log_ss', #diff follows engaged\n",
    "             'engaging_follow_diff_log_ss', #diff follows engaging\n",
    "             'engaged_follower_diff_engaging_following_log_ss',  #followings engaging\n",
    "             'engaged_following_diff_engaging_follower_log_ss', #followers engaging\n",
    "             'engaged_with_user_follower_count_log_ss', #engaged follower count\n",
    "             'engaging_user_follower_count_log_ss', #engaging follower count\n",
    "             'engaged_with_user_following_count_log_ss',  #engaged following count\n",
    "             'engaging_user_following_count_log_ss', #engaging following count\n",
    "             'PhotoCount_ss', 'VideoCount_ss', 'GIFCount_ss', 'linkCount_ss', #media\n",
    "             'engaged_with_user_follower_count_q', 'engaged_with_user_following_count_q', #Quantile\n",
    "             'engaged_with_user_account_creation_q', 'engaging_user_follower_count_q', #Quantile\n",
    "             'engaging_user_following_count_q', 'engaging_user_account_creation_q', #Quantile\n",
    "             'total_appearance_ss', 'perc_n_interactions_ss', 'perc_n_commented_ss', \n",
    "             'perc_n_liked_ss', 'perc_n_replied_ss', 'perc_n_retweeted_ss' #intentions\n",
    "             ]\n",
    "\n",
    "labels = ['indicator_reply', 'indicator_retweet', 'indicator_retweet_with_comment',\n",
    "          'indicator_like', 'indicator_interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd7dcb7430046f2a2c6e2bf1732a1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if submission:\n",
    "    cols_to_select = original + processed\n",
    "elif test:\n",
    "    cols_to_select = original + processed\n",
    "else:\n",
    "    cols_to_select = original + processed + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5902dbe8be7740f0a1e70fe7f918cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = df.select(cols_to_select)\n",
    "columns = columns2cast(new_df)\n",
    "new_df = cast_array2string(new_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5427e7ad40ba4a10a2d6e25028a3f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_types = {'bool': ['engaged_with_user_is_verified', 'engaging_user_is_verified', 'engagee_follows_engager'],\n",
    "              'id': ['tweet_id', 'engaged_with_user_id', 'engaging_user_id'], \n",
    "              'num': ['hashtagSumCount_ss', 'hashtagCount_ss', \n",
    "                      'domainCount_ss', \n",
    "                      'tweet_timestamp_to_engagee_account_creation_ss', #engagee time in twitter proxy\n",
    "                      'tweet_timestamp_to_engaging_account_creation_ss', #engaging time in twitter proxy\n",
    "                      'engaged_with_vs_engaging_follower_diff_log_ss', #followers engaged\n",
    "                      'engaged_with_vs_engaging_following_diff_log_ss', #followings engaged\n",
    "                      'engaged_follow_diff_log_ss', #diff follows engaged\n",
    "                      'engaging_follow_diff_log_ss', #diff follows engaging\n",
    "                      'engaged_follower_diff_engaging_following_log_ss',  #followings engaging\n",
    "                      'engaged_following_diff_engaging_follower_log_ss', #followers engaging\n",
    "                      'engaged_with_user_follower_count_log_ss', #engaged follower count\n",
    "                      'engaging_user_follower_count_log_ss', #engaging follower count\n",
    "                      'engaged_with_user_following_count_log_ss',  #engaged following count\n",
    "                      'engaging_user_following_count_log_ss', #engaging following count\n",
    "                      'PhotoCount_ss', 'VideoCount_ss', 'GIFCount_ss', 'linkCount_ss', #media\n",
    "                      'total_appearance_ss', 'perc_n_interactions_ss', 'perc_n_commented_ss', \n",
    "                      'perc_n_liked_ss', 'perc_n_replied_ss', 'perc_n_retweeted_ss' #intentions\n",
    "                     ], \n",
    "              'cat': ['tweetEncoded', 'languageEncoded',\n",
    "                      'tweet_timestamp_day_of_week', 'tweet_timestamp_week_of_month', 'tweet_timestamp_hour',\n",
    "                      'engaged_with_user_follower_count_q', 'engaged_with_user_following_count_q', #Quantile\n",
    "                      'engaged_with_user_account_creation_q', 'engaging_user_follower_count_q', #Quantile\n",
    "                      'engaging_user_following_count_q', 'engaging_user_account_creation_q', #Quantile\n",
    "                     ], \n",
    "              'ors': ['text_tokens'], \n",
    "              'unors':['hashtagEncoded', 'domainEncoded']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c878b80b3a9842cdbc094ebbf5a856dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, val in dict_types.items():\n",
    "    for column in val:\n",
    "        new_df = new_df.withColumnRenamed(column, column + '_' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf939b5c1134ccc90ef71bff3aef0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12434838"
     ]
    }
   ],
   "source": [
    "new_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MergeUserBucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c31ae19460b4bb485ff4438e529ffe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_user_bucket = spark.read.csv(map_user_bucket_path, schema= StructType([StructField('user_id', StringType()),\n",
    "                                                                           StructField('final_bucket', IntegerType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920b087ca2cf4a2abc2c7574e2a1faa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = new_df.join(map_user_bucket, new_df.engaged_with_user_id_id==map_user_bucket.user_id, how=\"left\")\n",
    "new_df = new_df.drop(\"user_id\")\n",
    "new_df = new_df.withColumnRenamed(\"final_bucket\", \"engaged_with_user_id_bucket\")\n",
    "\n",
    "new_df = new_df.join(map_user_bucket, new_df.engaging_user_id_id==map_user_bucket.user_id, how=\"left\")\n",
    "new_df = new_df.drop(\"user_id\")\n",
    "new_df = new_df.withColumnRenamed(\"final_bucket\", \"engaging_user_id_bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_submission_path)\n",
    "print(processed_test_path)\n",
    "print(processed_train_path)\n",
    "print(processed_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed291223d534733957054d38db9c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_submission_path = f\"hdfs:///submission-{suffix_sample}\"\n",
    "processed_test_path = f\"hdfs:///test-{suffix_sample}\"\n",
    "processed_train_path = f\"hdfs:///train-{suffix_sample}\"\n",
    "processed_val_path = f\"hdfs:///val-{suffix_sample}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bac04aa1fbd4dc69561cae5f03688b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test saved"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_submission_path)\n",
    "    print(\"Submission saved\")\n",
    "elif test:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_test_path)\n",
    "    print(\"Test saved\")\n",
    "elif training:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_train_path)\n",
    "    print(\"Train saved\")\n",
    "else:\n",
    "    new_df.write.option(\"header\",\"true\").csv(processed_val_path)\n",
    "    print(\"Valid saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPLACE FOR S3-DIST-CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StructType([StructField(\"text_tokens_ors\",StringType),\n",
    "            StructField(\"tweet_id_id\",StringType),\n",
    "            StructField(\"engaged_with_user_id_id\",StringType),\n",
    "            StructField(\"engaged_with_user_is_verified_bool\",BooleanType),\n",
    "            StructField(\"engaging_user_id_id\",StringType),\n",
    "            StructField(\"engaging_user_is_verified_bool\",BooleanType),\n",
    "            StructField(\"engagee_follows_engager_bool\",BooleanType),\n",
    "            StructField(\"hashtagEncoded_unors\",StringType),\n",
    "            StructField(\"hashtagSumCount_num\",IntegerType),\n",
    "            StructField(\"hashtagCount_num\",IntegerType),\n",
    "            StructField(\"domainEncoded_unors\",StringType),\n",
    "            StructField(\"domainCount_num\",IntegerType),\n",
    "            StructField(\"tweetEncoded_cat\",IntegerType),\n",
    "            StructField(\"languageEncoded_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_day_of_week_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_week_of_month_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_hour_cat\",StringType),\n",
    "            StructField(\"tweet_timestamp_to_engagee_account_creation_ss_num\",DoubleType),\n",
    "            StructField(\"tweet_timestamp_to_engaging_account_creation_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_vs_engaging_follower_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_vs_engaging_following_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_follow_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_follow_diff_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_follower_diff_engaging_following_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_following_diff_engaging_follower_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_user_follower_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_user_follower_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaged_with_user_following_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"engaging_user_following_count_log_ss_num\",DoubleType),\n",
    "            StructField(\"PhotoCount_num\",IntegerType),\n",
    "            StructField(\"VideoCount_num\",IntegerType),\n",
    "            StructField(\"GIFCount_num\",IntegerType),\n",
    "            StructField(\"linkCount_num\",IntegerType),\n",
    "            StructField(\"engaged_with_user_follower_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaged_with_user_following_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaged_with_user_account_creation_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_follower_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_following_count_q_cat\",DoubleType),\n",
    "            StructField(\"engaging_user_account_creation_q_cat\",DoubleType),\n",
    "            StructField(\"total_appearance_num\",LongType),\n",
    "            StructField(\"perc_n_interactions_num\",DoubleType),\n",
    "            StructField(\"perc_n_commented_num\",DoubleType),\n",
    "            StructField(\"perc_n_liked_num\",DoubleType),\n",
    "            StructField(\"perc_n_replied_num\",DoubleType),\n",
    "            StructField(\"perc_n_retweeted_num\",DoubleType),\n",
    "            StructField(\"indicator_reply\",IntegerType),\n",
    "            StructField(\"indicator_retweet\",IntegerType),\n",
    "            StructField(\"indicator_retweet_with_comment\",IntegerType),\n",
    "            StructField(\"indicator_like\",IntegerType),\n",
    "            StructField(\"indicator_interaction\",IntegerType)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
