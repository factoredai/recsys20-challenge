{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "# Goal\n",
    "Create a data pipeline for twitter challenge.\n",
    "\n",
    "# Methodology\n",
    "Create different features from the original data\n",
    "\n",
    "## Sections\n",
    "1. [**Requirements**](#Requirements)\n",
    "2. [**Functions**](#Functions)\n",
    "3. [**Inputs**](#Inputs)\n",
    "4. [**Pipeline**](#Pipeline)\n",
    "    - [**Indicators**](#Indicators)\n",
    "    - [**Intention_features**](#Intention_features)\n",
    "    - [**TopicEncodings**](#TopicEncodings)\n",
    "    - [**EngagingFollowsEngaged**](#EngagingFollowsEngaged)\n",
    "    - [**Hashtags**](#Hashtags)\n",
    "    - [**Domain**](#Domain)\n",
    "    - [**Language**](#Language)\n",
    "    - [**Media**](#Media)\n",
    "    - [**Links**](#Links)\n",
    "    - [**Tweet_type**](#Tweet_type)\n",
    "    - [**Timestamp_features**](#Timestamp_features)\n",
    "    - [**Followers_and_Followings_features**](#Followers_and_Followings_features)\n",
    "    - [**Quantile_Discretizer**](#Quantile_Discretizer)\n",
    "    - [**Intentions_join**](#Intentions_join)\n",
    "5. [**FeatureSelection**](#FeatureSelection)\n",
    "6. [**Imputation**](#Imputation)\n",
    "7. [**Validation**](#Validation)\n",
    "8. [**Saving_df**](#Saving_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#installing packages\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03602538eea4483902d8a4de0eff152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reconfiguring SparkContext\n",
    "sc.setCheckpointDir('hdfs:///twitter/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93ea52ae0884563b2ea6f4adef9612b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048M\n",
      "1000"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyspark\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (FloatType, DateType, StructType, StructField, StringType, LongType, \n",
    "    IntegerType, ArrayType, BooleanType, DoubleType, DecimalType)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, QuantileDiscretizer\n",
    "gc.enable()\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.sql.shuffle.partitions\", 1000).appName(\"twitter\").getOrCreate()\n",
    "print(spark.sparkContext.getConf().get('spark.driver.memory'))\n",
    "print(spark.sparkContext.getConf().get(\"spark.sql.shuffle.partitions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0542ec6b965149c8b4424a9efb4c049e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validator(df):\n",
    "    columns_w_nan = {}\n",
    "    for col in df.schema:\n",
    "        null_count = df.filter(F.col(col.name).isNull()).count()\n",
    "        if null_count>0:\n",
    "            columns_w_nan[col.name]=null_count\n",
    "    return columns_w_nan\n",
    "\n",
    "def hdfs_exists(path):\n",
    "    proc = subprocess.Popen(['hadoop', 'fs', '-test', '-e', path])\n",
    "    proc.communicate()\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"{path} does not exist\")\n",
    "        return False\n",
    "    else : \n",
    "        print(f\"{path} exist\")\n",
    "        return True\n",
    "    \n",
    "def reduce_dec(v):\n",
    "    result = np.around(v, decimals=4)\n",
    "    return result.tolist()\n",
    "reduce_dec_udf = F.udf(reduce_dec,  ArrayType(DoubleType()))\n",
    "\n",
    "def to_array_(v):\n",
    "    result = v.toArray()\n",
    "    result = np.around(result, decimals=4)\n",
    "    return result.tolist()\n",
    "vect2array = F.udf(to_array_,  ArrayType(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f660c0cd109c4a05a5792ab65a0c1701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_processed_schema(has_labels=True):\n",
    "    if has_labels:\n",
    "        schema = StructType([StructField('text_tokens_ors', StringType()),\n",
    "                             StructField('tweet_id_id', StringType()),\n",
    "                             StructField('engaged_with_user_id_id', StringType()),\n",
    "                             StructField('engaged_with_user_is_verified_bool', BooleanType()),\n",
    "                             StructField('engaging_user_id_id', StringType()),\n",
    "                             StructField('engaging_user_is_verified_bool', BooleanType()),\n",
    "                             StructField('engagee_follows_engager_bool', BooleanType()),\n",
    "                             StructField('hashtagEncoded_unors', StringType()),\n",
    "                             StructField('hashtagSumCount_ss_num', DoubleType()),\n",
    "                             StructField('hashtagCount_ss_num', DoubleType()),\n",
    "                             StructField('domainEncoded_unors', StringType()),\n",
    "                             StructField('domainCount_ss_num', DoubleType()),\n",
    "                             StructField('tweetEncoded_cat', IntegerType()),\n",
    "                             StructField('languageEncoded_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_day_of_week_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_week_of_month_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_hour_cat', StringType()),\n",
    "                             StructField('tweet_timestamp_to_engagee_account_creation_ss_num', DoubleType()),\n",
    "                             StructField('tweet_timestamp_to_engaging_account_creation_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_vs_engaging_follower_diff_log_ss_num', DoubleType()), \n",
    "                             StructField('engaged_with_vs_engaging_following_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_follow_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_follow_diff_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_follower_diff_engaging_following_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_following_diff_engaging_follower_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_follower_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_user_follower_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_following_count_log_ss_num', DoubleType()),\n",
    "                             StructField('engaging_user_following_count_log_ss_num', DoubleType()),\n",
    "                             StructField('PhotoCount_ss_num', DoubleType()),\n",
    "                             StructField('VideoCount_ss_num', DoubleType()),\n",
    "                             StructField('GIFCount_ss_num', DoubleType()),\n",
    "                             StructField('linkCount_ss_num', DoubleType()),\n",
    "                             StructField('engaged_with_user_follower_count_q_cat', DoubleType()),\n",
    "                             StructField('engaged_with_user_following_count_q_cat', DoubleType()),\n",
    "                             StructField('engaged_with_user_account_creation_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_follower_count_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_following_count_q_cat', DoubleType()),\n",
    "                             StructField('engaging_user_account_creation_q_cat', DoubleType()),\n",
    "                             StructField('total_appearance_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_interactions_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_commented_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_liked_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_replied_ss_num', DoubleType()),\n",
    "                             StructField('perc_n_retweeted_ss_num', DoubleType()),\n",
    "                             StructField('indicator_reply', IntegerType()),\n",
    "                             StructField('indicator_retweet', IntegerType()),\n",
    "                             StructField('indicator_retweet_with_comment', IntegerType()),\n",
    "                             StructField('indicator_like', IntegerType()),\n",
    "                             StructField('indicator_interaction', IntegerType()),\n",
    "                             StructField('engaged_with_user_id_bucket', IntegerType()),\n",
    "                             StructField('engaging_user_id_bucket', IntegerType())])\n",
    "    else:\n",
    "        schema = StructType([StructField('text_tokens_ors', StringType()),\n",
    "                         StructField('tweet_id_id', StringType()),\n",
    "                         StructField('engaged_with_user_id_id', StringType()),\n",
    "                         StructField('engaged_with_user_is_verified_bool', BooleanType()),\n",
    "                         StructField('engaging_user_id_id', StringType()),\n",
    "                         StructField('engaging_user_is_verified_bool', BooleanType()),\n",
    "                         StructField('engagee_follows_engager_bool', BooleanType()),\n",
    "                         StructField('hashtagEncoded_unors', StringType()),\n",
    "                         StructField('hashtagSumCount_ss_num', DoubleType()),\n",
    "                         StructField('hashtagCount_ss_num', DoubleType()),\n",
    "                         StructField('domainEncoded_unors', StringType()),\n",
    "                         StructField('domainCount_ss_num', DoubleType()),\n",
    "                         StructField('tweetEncoded_cat', IntegerType()),\n",
    "                         StructField('languageEncoded_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_day_of_week_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_week_of_month_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_hour_cat', StringType()),\n",
    "                         StructField('tweet_timestamp_to_engagee_account_creation_ss_num', DoubleType()),\n",
    "                         StructField('tweet_timestamp_to_engaging_account_creation_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_vs_engaging_follower_diff_log_ss_num', DoubleType()), \n",
    "                         StructField('engaged_with_vs_engaging_following_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_follow_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_follow_diff_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_follower_diff_engaging_following_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_following_diff_engaging_follower_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_follower_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_user_follower_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_following_count_log_ss_num', DoubleType()),\n",
    "                         StructField('engaging_user_following_count_log_ss_num', DoubleType()),\n",
    "                         StructField('PhotoCount_ss_num', DoubleType()),\n",
    "                         StructField('VideoCount_ss_num', DoubleType()),\n",
    "                         StructField('GIFCount_ss_num', DoubleType()),\n",
    "                         StructField('linkCount_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_follower_count_q_cat', DoubleType()),\n",
    "                         StructField('engaged_with_user_following_count_q_cat', DoubleType()),\n",
    "                         StructField('engaged_with_user_account_creation_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_follower_count_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_following_count_q_cat', DoubleType()),\n",
    "                         StructField('engaging_user_account_creation_q_cat', DoubleType()),\n",
    "                         StructField('total_appearance_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_interactions_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_commented_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_liked_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_replied_ss_num', DoubleType()),\n",
    "                         StructField('perc_n_retweeted_ss_num', DoubleType()),\n",
    "                         StructField('engaged_with_user_id_bucket', IntegerType()),\n",
    "                         StructField('engaging_user_id_bucket', IntegerType())])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28f72408e7e493e89658c742254fafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary_size={\"final-complete\": {\"val_size\": 500000, \n",
    "                                    \"train_size\": \"all\"}}\n",
    "\n",
    "training = False\n",
    "submission = False\n",
    "test = True\n",
    "\n",
    "bucket='bucket-name'\n",
    "s3_resource = boto3.resource('s3')\n",
    "top_k_languages = 30\n",
    "top_k_domains = 3000\n",
    "top_k_hashtags = 13000\n",
    "\n",
    "# Embeddings\n",
    "num_partitions=1000\n",
    "\n",
    "# Buckets\n",
    "partition_per_cluster = 100\n",
    "\n",
    "suffix_sample = \"final-complete\" #\"full\", \"small\", \"medium\", \"sub_medium\"\n",
    "data_path = \"final-data\"\n",
    "object_paths = \"final-artifacts\"\n",
    "\n",
    "val_size = dictionary_size[suffix_sample][\"val_size\"]\n",
    "train_size = dictionary_size[suffix_sample][\"train_size\"]\n",
    "\n",
    "bucket_s3 = s3_resource.Bucket(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9387ce0fc99841e4b415c2e5c286d0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#S3\n",
    "twitter_bucket_s3 = \"s3a://bucket-name\"\n",
    "trainining_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"training.tsv\")\n",
    "submission_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"submission.tsv\")\n",
    "test_path = os.path.join(twitter_bucket_s3, \"data\", \"raw\", \"final\", \"test.tsv\")\n",
    "\n",
    "# Splitted paths\n",
    "train_path = os.path.join(twitter_bucket_s3, data_path, \"train-\"+suffix_sample)\n",
    "val_path = os.path.join(twitter_bucket_s3, data_path, \"val-\"+suffix_sample)\n",
    "\n",
    "# Processed\n",
    "processed_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"train-\"+suffix_sample)\n",
    "processed_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"val-\"+suffix_sample)\n",
    "processed_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"submission-\"+suffix_sample)\n",
    "processed_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed\", \"test-\"+suffix_sample)\n",
    "processed_emb_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_emb_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_emb_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"submission-\"+suffix_sample)\n",
    "processed_emb_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-embeddings-final\", \n",
    "                                         \"test-\"+suffix_sample)\n",
    "processed_top_train_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                        \"train-\"+suffix_sample)\n",
    "processed_top_val_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                      \"val-\"+suffix_sample)\n",
    "processed_top_submission_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"submission-\"+suffix_sample)\n",
    "processed_top_test_path = os.path.join(twitter_bucket_s3, data_path, \"processed-topics\", \n",
    "                                             \"test-\"+suffix_sample)\n",
    "# Resources\n",
    "engaging_users_training_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-training\")\n",
    "engaging_users_submission_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-submission\")\n",
    "engaging_users_test_path = os.path.join(twitter_bucket_s3, data_path, \"engaging-users-test\")\n",
    "intentions_path = os.path.join(twitter_bucket_s3, data_path, \"intentions-\"+suffix_sample)\n",
    "map_user_bucket_path = os.path.join(twitter_bucket_s3, data_path, \"map_user_bucket\")\n",
    "\n",
    "topic_encodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"user_topics\")\n",
    "users_intime_path = os.path.join(twitter_bucket_s3, data_path, \"users_intime-\"+suffix_sample)\n",
    "\n",
    "# keys objects\n",
    "key_hashtag_mapping = os.path.join(object_paths, f'hashtag_mapping_{suffix_sample}.pkl')\n",
    "key_domain_mapping = os.path.join(object_paths, f'domain_mapping_{suffix_sample}.pkl')\n",
    "key_language_mapping = os.path.join(object_paths, f'language_mapping_{suffix_sample}.pkl')\n",
    "key_hashtag_count = os.path.join(object_paths, f'hashtag_count_{suffix_sample}.pkl')\n",
    "key_domain_count = os.path.join(object_paths, f'domain_count_{suffix_sample}.pkl')\n",
    "key_scaling_features = os.path.join(object_paths, f'scaling_dictionary_{suffix_sample}.pkl')\n",
    "key_diff_min = os.path.join(object_paths, f'diff_min_{suffix_sample}.pkl')\n",
    "key_impute_perc = os.path.join(object_paths, f'dict_mean_perc_{suffix_sample}.pkl')\n",
    "\n",
    "# s3+keys\n",
    "columns = [\"engaged_with_user_follower_count\", \"engaged_with_user_following_count\",\n",
    "           \"engaged_with_user_account_creation\", \"engaging_user_follower_count\",\n",
    "           \"engaging_user_following_count\", \"engaging_user_account_creation\"]\n",
    "qds_paths = {}\n",
    "for col in columns:\n",
    "    qds_paths[col] = os.path.join(twitter_bucket_s3, object_paths, f\"qs_{suffix_sample}_\" + col)\n",
    "    \n",
    "# Bucket pipeline\n",
    "users_buckets = os.path.join(twitter_bucket_s3, data_path, \"users_buckets\") #\n",
    "users_buckets_part_2 = os.path.join(twitter_bucket_s3, data_path, \"users_buckets_part_2\") #\n",
    "\n",
    "pipeline_kmeans_path = os.path.join(twitter_bucket_s3, object_paths, \"pipeline_id_encoding\")\n",
    "cluster_map_path = os.path.join(twitter_bucket_s3, data_path, \"cluster_map\")\n",
    "\n",
    "# Embeddings\n",
    "bert_embeddings_train = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"tweets_extended\")\n",
    "submission_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"submission-tweets-extended\")\n",
    "test_rawTweetEncodings_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"test-tweets-extended\")\n",
    "\n",
    "# Topics pipeline\n",
    "reduced_topics_path = os.path.join(twitter_bucket_s3, \"data\", \"textEncodings\", \"reducedTopics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hadoop fs -rm -r filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7f2253228048a699c00b02ac965928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_path = \"hdfs:///current-df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f17112e11b41e9a3a5eeeed22a98a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_submission_path, \n",
    "                                                schema=build_processed_schema(has_labels=False))\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    df = spark.read.option(\"header\",\"true\").csv(processed_test_path, \n",
    "                                                schema=build_processed_schema(has_labels=False))\n",
    "else:\n",
    "    if training:\n",
    "        print(\"Train\")\n",
    "        df = spark.read.option(\"header\",\"true\").csv(processed_train_path, \n",
    "                                                    schema=build_processed_schema(has_labels=True))\n",
    "    else:\n",
    "        print(\"Valid\")\n",
    "        df = spark.read.option(\"header\",\"true\").csv(processed_val_path, \n",
    "                                                    schema=build_processed_schema(has_labels=True))\n",
    "    \n",
    "df = df.withColumn(\"hash_tweet_id\", F.abs(F.hash(\"tweet_id_id\")%num_partitions))\n",
    "df = df.repartition(\"hash_tweet_id\")\n",
    "df.repartition(F.col(\"hash_tweet_id\")).write.option(\"header\",\"true\").partitionBy(\"hash_tweet_id\")\\\n",
    "            .mode(\"overwrite\").csv(current_path)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74887fb548c4f6eaf6076569d14dec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.option(\"header\",\"true\").csv(current_path).repartition(\"hash_tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5afa0256f7433b9ce982e7cad2a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000"
     ]
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186c027f554144b39ae7cfcdcba284f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12434838"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e600bbf96a94c4ab6f777b014b91d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_path_hdfs = \"hdfs:///test-embeddings\"\n",
    "submission_path_hdfs = \"hdfs:///submission-embeddings\"\n",
    "tweet_embeddings_path_hdfs = \"hdfs:///tweet-embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8a45b7b8aa4fb5a5daa1c48ae6a5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs:///test-embeddings does not exist\n",
      "Creating submission_path_hdfs\n",
      "DataFrame[tweet_id: string, embedding: string, cluster: int, hash_tweet_id_1: int]"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    if not(hdfs_exists(submission_path_hdfs)):\n",
    "        print(\"Creating submission_path_hdfs\")\n",
    "        submission_embeddings = spark.read.parquet(submission_rawTweetEncodings_path)\n",
    "        submission_embeddings = submission_embeddings.drop(\"tweet_hash\", \"pcs\")\n",
    "        submission_embeddings = submission_embeddings.withColumn(\"embedding\", vect2array(F.col(\"embedding\")))\n",
    "        submission_embeddings = submission_embeddings.withColumn(\"embedding\", F.col(\"embedding\").cast(StringType()))\n",
    "        submission_embeddings = submission_embeddings.withColumn(\"hash_tweet_id_1\",\n",
    "                                                         F.abs(F.hash(\"tweet_id\")%num_partitions))\n",
    "        submission_embeddings.repartition(F.col(\"hash_tweet_id_1\")).write.partitionBy(\"hash_tweet_id_1\")\\\n",
    "                    .mode(\"overwrite\").csv(submission_path_hdfs)\n",
    "        print(submission_embeddings)\n",
    "        del submission_embeddings\n",
    "    else:\n",
    "        print(\"Already exists submission_path_hdfs\")\n",
    "elif test:\n",
    "    if not(hdfs_exists(test_path_hdfs)):\n",
    "        print(\"Creating submission_path_hdfs\")\n",
    "        test_embeddings = spark.read.parquet(test_rawTweetEncodings_path)\n",
    "        test_embeddings = test_embeddings.drop(\"tweet_hash\", \"pcs\")\n",
    "        test_embeddings = test_embeddings.withColumn(\"embedding\", vect2array(F.col(\"embedding\")))\n",
    "        test_embeddings = test_embeddings.withColumn(\"embedding\", F.col(\"embedding\").cast(StringType()))\n",
    "        test_embeddings = test_embeddings.withColumn(\"hash_tweet_id_1\",\n",
    "                                                         F.abs(F.hash(\"tweet_id\")%num_partitions))\n",
    "        test_embeddings.repartition(F.col(\"hash_tweet_id_1\")).write.partitionBy(\"hash_tweet_id_1\")\\\n",
    "                    .mode(\"overwrite\").csv(test_path_hdfs)\n",
    "        print(test_embeddings)\n",
    "        del test_embeddings\n",
    "    else:\n",
    "        print(\"Already exists test_path_hdfs\")\n",
    "else:\n",
    "    if not(hdfs_exists(tweet_embeddings_path_hdfs)):\n",
    "        print(\"Creating tweets_embeddings\")\n",
    "        tweets_embeddings = spark.read.parquet(bert_embeddings_train) #60899572\n",
    "        tweets_embeddings = tweets_embeddings.drop(\"tweet_hash\", \"pcs\")\n",
    "        tweets_embeddings = tweets_embeddings.withColumn(\"embedding\", vect2array(F.col(\"embedding\")))\n",
    "        tweets_embeddings = tweets_embeddings.withColumn(\"embedding\", F.col(\"embedding\").cast(StringType()))\n",
    "        tweets_embeddings = tweets_embeddings.withColumn(\"hash_tweet_id_1\",\n",
    "                                                         F.abs(F.hash(\"tweet_id\")%num_partitions))\n",
    "        tweets_embeddings.repartition(F.col(\"hash_tweet_id_1\")).write.partitionBy(\"hash_tweet_id_1\")\\\n",
    "                    .mode(\"overwrite\").csv(tweet_embeddings_path_hdfs)\n",
    "        print(tweets_embeddings)\n",
    "        del tweets_embeddings\n",
    "    else:\n",
    "        print(\"Already exists tweets_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e908974783e04e1cbb3fcdb243b746d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "1000"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    print(\"Submission\")\n",
    "    schema = StructType([StructField('tweet_id', StringType()),\n",
    "                         StructField('embedding', StringType()),\n",
    "                         StructField(\"cluster\", IntegerType()),\n",
    "                         StructField('hash_tweet_id_1', IntegerType())])\n",
    "    tweets_embeddings = spark.read.csv(submission_path_hdfs, \n",
    "                                           schema=schema).repartition(\"hash_tweet_id_1\")\n",
    "    print(tweets_embeddings.rdd.getNumPartitions())\n",
    "elif test:\n",
    "    print(\"Test\")\n",
    "    schema = StructType([StructField('tweet_id', StringType()),\n",
    "                         StructField('embedding', StringType()),\n",
    "                         StructField(\"cluster\", IntegerType()),\n",
    "                         StructField('hash_tweet_id_1', IntegerType())])\n",
    "    tweets_embeddings = spark.read.csv(test_path_hdfs, \n",
    "                                           schema=schema).repartition(\"hash_tweet_id_1\")\n",
    "    print(tweets_embeddings.rdd.getNumPartitions())\n",
    "else:\n",
    "    print(\"Training\")\n",
    "    schema = StructType([StructField('tweet_id', StringType()),\n",
    "                         StructField('embedding', StringType()),\n",
    "                         StructField(\"cluster\", IntegerType()),\n",
    "                         StructField('hash_tweet_id_1', IntegerType())])\n",
    "    tweets_embeddings = spark.read.csv(tweet_embeddings_path_hdfs, \n",
    "                                       schema=schema).repartition(\"hash_tweet_id_1\")\n",
    "    print(tweets_embeddings.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e820efd2fa4ebaa0879ddb01ae5806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8671930"
     ]
    }
   ],
   "source": [
    "tweets_embeddings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894813bf71064b6a980d7ebe4fa7048a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.join(tweets_embeddings, \n",
    "             (df.tweet_id_id==tweets_embeddings.tweet_id), \n",
    "             how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1050c1d931de4d71bd67a838ebf55b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}"
     ]
    }
   ],
   "source": [
    "validator(df.select(\"cluster\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a871865f55d64bc999ae549be6058eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop(\"hash_tweet_id_1\", \"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09382d5bf4457fa0fedfe23435b982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission or Test"
     ]
    }
   ],
   "source": [
    "if submission or test:\n",
    "    print(\"Submission or Test\")\n",
    "    columns = ['embedding', 'tweet_id_id', 'engaged_with_user_id_id', 'engaged_with_user_is_verified_bool',\n",
    "               'engaging_user_id_id', 'engaging_user_is_verified_bool', 'engagee_follows_engager_bool', \n",
    "               'hashtagEncoded_unors', 'hashtagSumCount_ss_num', 'hashtagCount_ss_num', 'domainEncoded_unors', \n",
    "               'domainCount_ss_num', 'tweetEncoded_cat', 'languageEncoded_cat', 'tweet_timestamp_day_of_week_cat',\n",
    "               'tweet_timestamp_hour_cat',\n",
    "               'tweet_timestamp_to_engagee_account_creation_ss_num', \n",
    "               'tweet_timestamp_to_engaging_account_creation_ss_num',\n",
    "               'engaged_with_vs_engaging_follower_diff_log_ss_num', \n",
    "               'engaged_with_vs_engaging_following_diff_log_ss_num', 'engaged_follow_diff_log_ss_num', \n",
    "               'engaging_follow_diff_log_ss_num', 'engaged_follower_diff_engaging_following_log_ss_num', \n",
    "               'engaged_following_diff_engaging_follower_log_ss_num', 'engaged_with_user_follower_count_log_ss_num', \n",
    "               'engaging_user_follower_count_log_ss_num', 'engaged_with_user_following_count_log_ss_num', \n",
    "               'engaging_user_following_count_log_ss_num', 'PhotoCount_ss_num', 'VideoCount_ss_num', \n",
    "               'GIFCount_ss_num', 'linkCount_ss_num', 'engaged_with_user_follower_count_q_cat', \n",
    "               'engaged_with_user_following_count_q_cat', 'engaged_with_user_account_creation_q_cat', \n",
    "               'engaging_user_follower_count_q_cat', 'engaging_user_following_count_q_cat', \n",
    "               'engaging_user_account_creation_q_cat', 'total_appearance_ss_num', 'perc_n_interactions_ss_num', \n",
    "               'perc_n_commented_ss_num', 'perc_n_liked_ss_num', 'perc_n_replied_ss_num', 'perc_n_retweeted_ss_num', \n",
    "               'engaged_with_user_id_bucket', 'engaging_user_id_bucket', 'cluster']\n",
    "else:\n",
    "    print(\"Training\")\n",
    "    columns = ['embedding', 'tweet_id_id', 'engaged_with_user_id_id', 'engaged_with_user_is_verified_bool',\n",
    "               'engaging_user_id_id', 'engaging_user_is_verified_bool', 'engagee_follows_engager_bool', \n",
    "               'hashtagEncoded_unors', 'hashtagSumCount_ss_num', 'hashtagCount_ss_num', 'domainEncoded_unors', \n",
    "               'domainCount_ss_num', 'tweetEncoded_cat', 'languageEncoded_cat', 'tweet_timestamp_day_of_week_cat',\n",
    "               'tweet_timestamp_hour_cat',\n",
    "               'tweet_timestamp_to_engagee_account_creation_ss_num', \n",
    "               'tweet_timestamp_to_engaging_account_creation_ss_num',\n",
    "               'engaged_with_vs_engaging_follower_diff_log_ss_num', \n",
    "               'engaged_with_vs_engaging_following_diff_log_ss_num', 'engaged_follow_diff_log_ss_num', \n",
    "               'engaging_follow_diff_log_ss_num', 'engaged_follower_diff_engaging_following_log_ss_num', \n",
    "               'engaged_following_diff_engaging_follower_log_ss_num', 'engaged_with_user_follower_count_log_ss_num', \n",
    "               'engaging_user_follower_count_log_ss_num', 'engaged_with_user_following_count_log_ss_num', \n",
    "               'engaging_user_following_count_log_ss_num', 'PhotoCount_ss_num', 'VideoCount_ss_num', \n",
    "               'GIFCount_ss_num', 'linkCount_ss_num', 'engaged_with_user_follower_count_q_cat', \n",
    "               'engaged_with_user_following_count_q_cat', 'engaged_with_user_account_creation_q_cat', \n",
    "               'engaging_user_follower_count_q_cat', 'engaging_user_following_count_q_cat', \n",
    "               'engaging_user_account_creation_q_cat', 'total_appearance_ss_num', 'perc_n_interactions_ss_num', \n",
    "               'perc_n_commented_ss_num', 'perc_n_liked_ss_num', 'perc_n_replied_ss_num', 'perc_n_retweeted_ss_num', \n",
    "               'indicator_reply', 'indicator_retweet', 'indicator_retweet_with_comment', 'indicator_like', \n",
    "               'indicator_interaction', 'engaged_with_user_id_bucket', 'engaging_user_id_bucket', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc1e9d52bc942cf882fbdea0a86a507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df = df.select(columns)\n",
    "new_df = new_df.withColumnRenamed(\"embedding\", \"embedding_ors\")\n",
    "new_df = new_df.withColumnRenamed(\"cluster\", \"cluster_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60a6c0ff3ba4b19a8457aa8ac74750a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000"
     ]
    }
   ],
   "source": [
    "new_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db46ee8758240779ca9c3dbe3a4dcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[embedding_ors: string, tweet_id_id: string, engaged_with_user_id_id: string, engaged_with_user_is_verified_bool: string, engaging_user_id_id: string, engaging_user_is_verified_bool: string, engagee_follows_engager_bool: string, hashtagEncoded_unors: string, hashtagSumCount_ss_num: string, hashtagCount_ss_num: string, domainEncoded_unors: string, domainCount_ss_num: string, tweetEncoded_cat: string, languageEncoded_cat: string, tweet_timestamp_day_of_week_cat: string, tweet_timestamp_hour_cat: string, tweet_timestamp_to_engagee_account_creation_ss_num: string, tweet_timestamp_to_engaging_account_creation_ss_num: string, engaged_with_vs_engaging_follower_diff_log_ss_num: string, engaged_with_vs_engaging_following_diff_log_ss_num: string, engaged_follow_diff_log_ss_num: string, engaging_follow_diff_log_ss_num: string, engaged_follower_diff_engaging_following_log_ss_num: string, engaged_following_diff_engaging_follower_log_ss_num: string, engaged_with_user_follower_count_log_ss_num: string, engaging_user_follower_count_log_ss_num: string, engaged_with_user_following_count_log_ss_num: string, engaging_user_following_count_log_ss_num: string, PhotoCount_ss_num: string, VideoCount_ss_num: string, GIFCount_ss_num: string, linkCount_ss_num: string, engaged_with_user_follower_count_q_cat: string, engaged_with_user_following_count_q_cat: string, engaged_with_user_account_creation_q_cat: string, engaging_user_follower_count_q_cat: string, engaging_user_following_count_q_cat: string, engaging_user_account_creation_q_cat: string, total_appearance_ss_num: string, perc_n_interactions_ss_num: string, perc_n_commented_ss_num: string, perc_n_liked_ss_num: string, perc_n_replied_ss_num: string, perc_n_retweeted_ss_num: string, engaged_with_user_id_bucket: string, engaging_user_id_bucket: string, cluster_cat: int]"
     ]
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2006f634479943ada4e261471b2a5fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test saved"
     ]
    }
   ],
   "source": [
    "if submission:\n",
    "    current_new_df_path = \"hdfs:///submission-embeddings-final\"\n",
    "    new_df.write.option(\"header\",\"true\").mode(\"overwrite\").csv(current_new_df_path)\n",
    "    print(\"Submission saved\")\n",
    "elif test:\n",
    "    current_new_df_path = \"hdfs:///test-embeddings-final\"\n",
    "    new_df.write.option(\"header\",\"true\").mode(\"overwrite\").csv(current_new_df_path)\n",
    "    print(\"Test saved\")\n",
    "else:\n",
    "    if training:\n",
    "        current_new_df_path = \"hdfs:///train-embeddings\"\n",
    "        new_df.write.option(\"header\",\"true\").mode(\"overwrite\").csv(current_new_df_path)\n",
    "        print(\"Train saved\")\n",
    "    else:\n",
    "        current_new_df_path = \"hdfs:///val-embeddings\"\n",
    "        new_df.write.option(\"header\",\"true\").mode(\"overwrite\").csv(current_new_df_path)\n",
    "        print(\"Valid saved\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy to s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e0916d54884955a2f8545ff425ba85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = spark.read.option(\"header\",\"true\").csv(\"hdfs:///train-embeddings\").coalesce(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2365ac8268540cfa8449df46d1524aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000"
     ]
    }
   ],
   "source": [
    "train_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aadcae43b8b4806b17e324340a5c7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smaller_train = train_df.sample(withReplacement=False,\n",
    "                                fraction=0.45,\n",
    "                                seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91787d1e21fe4520937e9b8f68a94964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000"
     ]
    }
   ],
   "source": [
    "smaller_train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eebf780d3904fd5bad72123fbf1ccad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train small saved"
     ]
    }
   ],
   "source": [
    "smaller_new_df_path = \"hdfs:///smaller-train-embeddings\"\n",
    "smaller_train.write.option(\"header\",\"true\").mode(\"overwrite\").csv(smaller_new_df_path)\n",
    "print(\"Train small saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
